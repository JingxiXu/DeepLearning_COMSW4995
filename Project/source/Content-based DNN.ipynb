{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Lambda\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-12 21:45:06\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns in the data frame\n",
    "def _CAT_NUM():\n",
    "    global CATEGORICAL, NUMERICAL\n",
    "    CATEGORICAL = [\n",
    "        'msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', \n",
    "        'genre_ids', 'artist_name', 'composer', 'lyricist', 'language', \n",
    "        'city', 'gender', 'registered_via',\n",
    "    ]\n",
    "    UNDECIDED = [\n",
    "        'song_year',\n",
    "        'registration_year', 'registration_month', 'registration_day', 'expiration_year', 'expiration_month', 'expiration_day'\n",
    "    ]\n",
    "    NUMERICAL = [\n",
    "        'song_length', 'age', 'weird_age', 'validate_days',\n",
    "        'count_song_played', 'count_artist_played', \n",
    "        'genre_count', 'lyricist_count', 'composer_count', 'artist_count', \n",
    "        'is_featured', 'artist_composer', 'artist_composer_lyricist', 'song_lang_boolean', 'smaller_song'\n",
    "    ]\n",
    "    NUMERICAL += UNDECIDED\n",
    "\n",
    "def _check_CAT_NUM():\n",
    "    print(len(df_train.columns),\n",
    "          len(set(CATEGORICAL).union(NUMERICAL)),\n",
    "          len(set(CATEGORICAL).intersection(NUMERICAL)))\n",
    "\n",
    "\n",
    "_CAT_NUM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../input/'\n",
    "df_train = pd.read_csv(input_dir + \"train.csv\")\n",
    "df_test  = pd.read_csv(input_dir + 'test.csv')\n",
    "df_songs = pd.read_csv(input_dir + 'songs.csv')\n",
    "df_song_extra = pd.read_csv(input_dir + \"song_extra_info.csv\")\n",
    "df_members = pd.read_csv(input_dir + \"members.csv\", parse_dates=[\"registration_init_time\",\"expiration_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['msno', 'song_id', 'source_system_tab', 'source_screen_name',\n",
       "       'source_type', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Simple member related and song related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# member related\n",
    "df_members.rename(columns={'bd': 'age'}, inplace=True)\n",
    "df_members.loc[df_members['age'] < 5, 'age'] = 0\n",
    "df_members.loc[df_members['age'] >= 80, 'age'] = 0\n",
    "df_members['weird_age'] = 0\n",
    "df_members.loc[df_members['age'] == 0, 'weird_age'] = 1\n",
    "df_members['validate_days'] = (df_members['expiration_date'] - df_members['registration_init_time']).dt.days.astype(int)\n",
    "\n",
    "df_members['registration_year'] = df_members['registration_init_time'].dt.year.astype(int)\n",
    "df_members['registration_month'] = df_members['registration_init_time'].dt.month.astype(int)\n",
    "df_members['registration_day'] = df_members['registration_init_time'].dt.day.astype(int)\n",
    "\n",
    "df_members['expiration_year'] = df_members['expiration_date'].dt.year.astype(int)\n",
    "df_members['expiration_month'] = df_members['expiration_date'].dt.month.astype(int)\n",
    "df_members['expiration_day'] = df_members['expiration_date'].dt.day.astype(int)\n",
    "\n",
    "df_members.drop(['registration_init_time', 'expiration_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song related\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df_song_extra['song_year'] = df_song_extra['isrc'].apply(isrc_to_year)\n",
    "df_song_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "\n",
    "# 1000 <=> 1s\n",
    "df_songs['song_length'] /= 1000.0\n",
    "df_songs.loc[df_songs['song_length'] > 1800, 'song_length'] = 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join train and song based on song_id\n",
    "# left join train and members based on msno(user id)\n",
    "# left join train and song_extra based on song_id\n",
    "df_train = df_train.merge(df_songs, how=\"left\", on=\"song_id\")\n",
    "df_train = df_train.merge(df_members, how=\"left\", on=\"msno\")\n",
    "df_train = df_train.merge(df_song_extra, how='left', on='song_id')\n",
    "\n",
    "df_test  = df_test.merge(df_songs, how=\"left\", on=\"song_id\")\n",
    "df_test  = df_test.merge(df_members, how=\"left\", on=\"msno\")\n",
    "df_test = df_test.merge(df_song_extra, how='left', on='song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in ['registered_via', 'city', 'language']:\n",
    "#     df_train[col] = df_train[col].astype(str)\n",
    "#     df_test[col] = df_test[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN = 'Unknown'\n",
    "col_fill_with_unknown = [\n",
    "    'source_system_tab', 'source_screen_name', 'source_type', \n",
    "    'gender', \n",
    "    'genre_ids', 'artist_name', 'composer', 'lyricist', 'language'\n",
    "]\n",
    "for col in col_fill_with_unknown:\n",
    "    df_train[col].fillna(value=UNKNOWN, inplace=True)\n",
    "    df_test[col].fillna(value=UNKNOWN, inplace=True)\n",
    "\n",
    "df_train['song_length'].fillna(value=230,inplace=True)\n",
    "df_test['song_length'].fillna(value=230,inplace=True)\n",
    "\n",
    "fill_in_value = df_train['song_year'].median()\n",
    "df_train['song_year'].fillna(value=fill_in_value, inplace=True)\n",
    "df_test['song_year'].fillna(value=fill_in_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Count and binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count(x):\n",
    "    if x == UNKNOWN:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';', '„ÄÅ', ','])) + 1\n",
    "\n",
    "df_train['genre_count'] = df_train['genre_ids'].apply(_count).astype(int)\n",
    "df_test['genre_count'] = df_test['genre_ids'].apply(_count).astype(int)\n",
    "\n",
    "df_train['lyricist_count'] = df_train['lyricist'].apply(_count).astype(int)\n",
    "df_test['lyricist_count'] = df_test['lyricist'].apply(_count).astype(int)\n",
    "\n",
    "df_train['composer_count'] = df_train['composer'].apply(_count).astype(int)\n",
    "df_test['composer_count'] = df_test['composer'].apply(_count).astype(int)\n",
    "\n",
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "df_train['is_featured'] = df_train['artist_name'].apply(is_featured).astype(np.int8)\n",
    "df_test['is_featured'] = df_test['artist_name'].apply(is_featured).astype(np.int8)\n",
    "\n",
    "def artist_count(x):\n",
    "    if x == UNKNOWN:\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&') + 1\n",
    "df_train['artist_count'] = df_train['artist_name'].apply(artist_count).astype(np.int8)\n",
    "df_test['artist_count'] = df_test['artist_name'].apply(artist_count).astype(np.int8)\n",
    "\n",
    "# if artist is same as composer\n",
    "df_train['artist_composer'] = (df_train['artist_name'] == df_train['composer']).astype(np.int8)\n",
    "df_test['artist_composer'] = (df_test['artist_name'] == df_test['composer']).astype(np.int8)\n",
    "\n",
    "# if artist, lyricist and composer are all three same\n",
    "df_train['artist_composer_lyricist'] = ((df_train['artist_name'] == df_train['composer']) \n",
    "                                        & (df_train['artist_name'] == df_train['lyricist']) \n",
    "                                        & (df_train['composer'] == df_train['lyricist'])).astype(np.int8)\n",
    "df_test['artist_composer_lyricist'] = ((df_test['artist_name'] == df_test['composer']) \n",
    "                                       & (df_test['artist_name'] == df_test['lyricist']) \n",
    "                                       & (df_test['composer'] == df_test['lyricist'])).astype(np.int8)\n",
    "\n",
    "# is song language 17 or 45. \n",
    "def song_lang_boolean(x):\n",
    "    if '17.0' in str(x) or '45.0' in str(x):\n",
    "        return 1\n",
    "    return 0\n",
    "df_train['song_lang_boolean'] = df_train['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "df_test['song_lang_boolean'] = df_test['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "\n",
    "# smaller song\n",
    "_mean_song_length = np.mean(df_train['song_length'])\n",
    "def smaller_song(x):\n",
    "    if x < _mean_song_length:\n",
    "        return 1\n",
    "    return 0\n",
    "df_train['smaller_song'] = df_train['song_length'].apply(smaller_song).astype(np.int8)\n",
    "df_test['smaller_song'] = df_test['song_length'].apply(smaller_song).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Historical statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in df_train['song_id'].value_counts().iteritems()}\n",
    "_dict_count_song_played_test = {k: v for k, v in df_test['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_song_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "df_train['count_song_played'] = df_train['song_id'].apply(count_song_played).astype(np.int64)\n",
    "df_test['count_song_played'] = df_test['song_id'].apply(count_song_played).astype(np.int64)\n",
    "del _dict_count_song_played_test\n",
    "del _dict_count_song_played_train\n",
    "\n",
    "# number of times the artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in df_train['artist_name'].value_counts().iteritems()}\n",
    "_dict_count_artist_played_test = {k: v for k, v in df_test['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_artist_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "df_train['count_artist_played'] = df_train['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "df_test['count_artist_played'] = df_test['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "del _dict_count_artist_played_train\n",
    "del _dict_count_artist_played_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 standarize numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_length\t244.9424990054791\t59.95896238525197\n",
      "age\t17.2371374375154\t15.560832070689322\n",
      "weird_age\t0.3997230467353212\t0.4898413341675067\n",
      "validate_days\t1627.9613096343464\t1128.6731207827263\n",
      "count_song_played\t1640.9239731298944\t2576.840783303741\n",
      "count_artist_played\t39826.780881332736\t69878.12930279176\n",
      "genre_count\t1.0373533125003898\t0.29489515136292566\n",
      "lyricist_count\t0.869041716221041\t1.2176895831574315\n",
      "composer_count\t1.3887604037076386\t1.6258642833509023\n",
      "artist_count\t1.03012286955\t0.190183271661\n",
      "is_featured\t0.00206589893646\t0.0454051869068\n",
      "artist_composer\t0.0302623492393\t0.171308316954\n",
      "artist_composer_lyricist\t0.0170903966672\t0.129608313811\n",
      "song_lang_boolean\t0.0335527958427\t0.180075000302\n",
      "smaller_song\t0.525266970097\t0.499361172121\n",
      "song_year\t2011.447105748922\t6.458415090813096\n",
      "registration_year\t2012.7405063668616\t3.01886048129776\n",
      "registration_month\t6.8323058284077165\t3.7007223813226187\n",
      "registration_day\t15.815322786373226\t8.7685480878986\n",
      "expiration_year\t2017.071606895529\t0.3982535484067784\n",
      "expiration_month\t8.341741514443129\t2.5113602605637504\n",
      "expiration_day\t15.623375007353522\t9.107233920245156\n"
     ]
    }
   ],
   "source": [
    "# Normalize numerical data\n",
    "for col in NUMERICAL:\n",
    "    mean = np.mean(df_train[col])\n",
    "    stdd = np.std(df_train[col])\n",
    "    df_train[col] = (df_train[col] - mean) / stdd\n",
    "    df_test[col]  = (df_test[col] - mean) / stdd\n",
    "    print(col, mean, stdd, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparing Data for keras\n",
    "decide features' data types and encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-08 11:46:26\n",
      "msno...song_id...source_system_tab...source_screen_name...source_type...genre_ids...artist_name...composer...lyricist...language...city...gender...registered_via...2017-12-08 11:52:42\n"
     ]
    }
   ],
   "source": [
    "# it would take < 10 min\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "# when i will use the information of these again? -- when i embed, i would like to use their size\n",
    "encoder_dict = dict()\n",
    "for col in CATEGORICAL:\n",
    "    print(col, end='...')\n",
    "    df_train[col] = df_train[col].astype(str)\n",
    "    df_test[col]  = df_test[col].astype(str)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df_train[col].append(df_test[col]))\n",
    "    encoder_dict[col] = encoder\n",
    "    df_train[col] = encoder.transform(df_train[col])\n",
    "    df_test[col]  = encoder.transform(df_test[col])\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "df_train.to_csv('../output/df_train.csv')\n",
    "df_test.to_csv('../output/df_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start from here if previous steps are executed before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "df_train = pd.read_csv('../output/df_train.csv')\n",
    "df_test  = pd.read_csv('../output/df_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Split the data\n",
    "randomly split the data into two parts (10%/90%) for train/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "perm = np.random.permutation(len(df_train))\n",
    "# perm = list(range(len(df_train)))\n",
    "\n",
    "trn_cnt = int(len(df_train) * 0.9)\n",
    "X_trn = df_train.loc[perm[:trn_cnt], :]\n",
    "# X_trn = df_train\n",
    "X_val = df_train.loc[perm[trn_cnt:], :]\n",
    "X_last = df_train[trn_cnt:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Train the memorization DNN: Pseudo MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def mem_model():\n",
    "    vocab_size = int(max(df_train['msno'].max(), df_test['msno'].max()) + 1)\n",
    "    user_embeddings = Embedding(\n",
    "        input_dim = vocab_size,\n",
    "        output_dim = 64,\n",
    "        embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "        embeddings_regularizer = l2(1e-4),\n",
    "        input_length = 1,\n",
    "        name = 'user_embed',\n",
    "        trainable=True)\n",
    "    \n",
    "    vocab_size = int(max(df_train['song_id'].max(), df_test['song_id'].max()) + 1)\n",
    "    song_embeddings = Embedding(\n",
    "        input_dim = vocab_size,\n",
    "        output_dim = 64,\n",
    "        embeddings_initializer=RandomUniform(minval=-0.1, maxval=0.1),\n",
    "        embeddings_regularizer=l2(1e-4),\n",
    "        input_length=1,\n",
    "        name = 'song_embed',\n",
    "        trainable=True)\n",
    "\n",
    "    # embedding of user id\n",
    "    uid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_usr = user_embeddings(uid_input)\n",
    "    embedded_usr = Reshape((64,))(embedded_usr)\n",
    "\n",
    "    # embedding of song id\n",
    "    sid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_song = song_embeddings(sid_input)\n",
    "    embedded_song = Reshape((64,))(embedded_song)\n",
    "\n",
    "    # dot production of embedded vectors\n",
    "    preds = dot([embedded_usr, embedded_song], axes=1)\n",
    "    # concatenate two embedded vectors together (64 + 64) with the dot production (1) as a 129-dim vector\n",
    "    preds = concatenate([embedded_usr, embedded_song, preds], name='mem_latent')\n",
    "    \n",
    "    # 128-dim hidden layer\n",
    "    preds = Dense(128, activation='relu', name='mem_dense1')(preds)\n",
    "    # dropout layer\n",
    "    preds = Dropout(0.5, name='mem_dropout1')(preds)\n",
    "    \n",
    "    # output layer\n",
    "    preds = Dense(1, activation='sigmoid', name='mem_output')(preds)\n",
    "\n",
    "    model = Model(inputs=[uid_input, sid_input], outputs=preds)\n",
    "    opt = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embed (Embedding)          (None, 1, 64)        2201792     input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "song_embed (Embedding)          (None, 1, 64)        26869696    input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_123 (Reshape)           (None, 64)           0           user_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_124 (Reshape)           (None, 64)           0           song_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_15 (Dot)                    (None, 1)            0           reshape_123[0][0]                \n",
      "                                                                 reshape_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mem_latent (Concatenate)        (None, 129)          0           reshape_123[0][0]                \n",
      "                                                                 reshape_124[0][0]                \n",
      "                                                                 dot_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mem_dense1 (Dense)              (None, 128)          16640       mem_latent[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mem_output (Dense)              (None, 1)            129         mem_dense1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 29,088,257\n",
      "Trainable params: 29,088,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 6639676 samples, validate on 737742 samples\n",
      "Epoch 1/60\n",
      "6639676/6639676 [==============================] - 113s 17us/step - loss: 1.6846 - acc: 0.6442 - val_loss: 0.6343 - val_acc: 0.6631\n",
      "Epoch 2/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.6246 - acc: 0.6666 - val_loss: 0.6196 - val_acc: 0.6670\n",
      "Epoch 3/60\n",
      "6639676/6639676 [==============================] - 110s 17us/step - loss: 0.6152 - acc: 0.6732 - val_loss: 0.6136 - val_acc: 0.6734\n",
      "Epoch 4/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.6103 - acc: 0.6774 - val_loss: 0.6105 - val_acc: 0.6764\n",
      "Epoch 5/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.6071 - acc: 0.6811 - val_loss: 0.6078 - val_acc: 0.6803\n",
      "Epoch 6/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.6038 - acc: 0.6853 - val_loss: 0.6050 - val_acc: 0.6835\n",
      "Epoch 7/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.6003 - acc: 0.6892 - val_loss: 0.6027 - val_acc: 0.6865\n",
      "Epoch 8/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5983 - acc: 0.6922 - val_loss: 0.6020 - val_acc: 0.6889\n",
      "Epoch 9/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5971 - acc: 0.6955 - val_loss: 0.6009 - val_acc: 0.6919\n",
      "Epoch 10/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5951 - acc: 0.6995 - val_loss: 0.6000 - val_acc: 0.6956\n",
      "Epoch 11/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5919 - acc: 0.7053 - val_loss: 0.5992 - val_acc: 0.6994\n",
      "Epoch 12/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5882 - acc: 0.7125 - val_loss: 0.5993 - val_acc: 0.7039\n",
      "Epoch 13/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5831 - acc: 0.7219 - val_loss: 0.6026 - val_acc: 0.7074\n",
      "Epoch 14/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5760 - acc: 0.7340 - val_loss: 0.6107 - val_acc: 0.7086\n",
      "Epoch 15/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5671 - acc: 0.7477 - val_loss: 0.6218 - val_acc: 0.7093\n",
      "Epoch 16/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.5576 - acc: 0.7613 - val_loss: 0.6373 - val_acc: 0.7072\n",
      "Epoch 17/60\n",
      "6639676/6639676 [==============================] - 106s 16us/step - loss: 0.5489 - acc: 0.7729 - val_loss: 0.6533 - val_acc: 0.7046\n",
      "Epoch 18/60\n",
      "6639676/6639676 [==============================] - 106s 16us/step - loss: 0.5415 - acc: 0.7819 - val_loss: 0.6668 - val_acc: 0.7032\n",
      "Epoch 19/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5357 - acc: 0.7890 - val_loss: 0.6794 - val_acc: 0.7012\n",
      "Epoch 20/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5309 - acc: 0.7944 - val_loss: 0.6889 - val_acc: 0.6999\n",
      "Epoch 21/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5269 - acc: 0.7985 - val_loss: 0.6968 - val_acc: 0.6986\n",
      "Epoch 22/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5235 - acc: 0.8018 - val_loss: 0.7045 - val_acc: 0.6974\n",
      "Epoch 23/60\n",
      "6639676/6639676 [==============================] - 106s 16us/step - loss: 0.5205 - acc: 0.8048 - val_loss: 0.7108 - val_acc: 0.6963\n",
      "Epoch 24/60\n",
      "6639676/6639676 [==============================] - 106s 16us/step - loss: 0.5181 - acc: 0.8068 - val_loss: 0.7169 - val_acc: 0.6955\n",
      "Epoch 25/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5159 - acc: 0.8087 - val_loss: 0.7220 - val_acc: 0.6950\n",
      "Epoch 26/60\n",
      "6639676/6639676 [==============================] - 107s 16us/step - loss: 0.5139 - acc: 0.8103 - val_loss: 0.7265 - val_acc: 0.6940\n",
      "Epoch 27/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.5122 - acc: 0.8116 - val_loss: 0.7319 - val_acc: 0.6940\n",
      "Epoch 28/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5106 - acc: 0.8128 - val_loss: 0.7341 - val_acc: 0.6933\n",
      "Epoch 29/60\n",
      "6639676/6639676 [==============================] - 110s 17us/step - loss: 0.5092 - acc: 0.8138 - val_loss: 0.7374 - val_acc: 0.6930\n",
      "Epoch 30/60\n",
      "6639676/6639676 [==============================] - 110s 17us/step - loss: 0.5078 - acc: 0.8147 - val_loss: 0.7416 - val_acc: 0.6922\n",
      "Epoch 31/60\n",
      "6639676/6639676 [==============================] - 111s 17us/step - loss: 0.5068 - acc: 0.8154 - val_loss: 0.7425 - val_acc: 0.6917\n",
      "Epoch 32/60\n",
      "6639676/6639676 [==============================] - 110s 16us/step - loss: 0.5056 - acc: 0.8162 - val_loss: 0.7462 - val_acc: 0.6914\n",
      "Epoch 33/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5046 - acc: 0.8170 - val_loss: 0.7481 - val_acc: 0.6911\n",
      "Epoch 34/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5036 - acc: 0.8175 - val_loss: 0.7504 - val_acc: 0.6906\n",
      "Epoch 35/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5027 - acc: 0.8181 - val_loss: 0.7514 - val_acc: 0.6912\n",
      "Epoch 36/60\n",
      "6639676/6639676 [==============================] - 111s 17us/step - loss: 0.5018 - acc: 0.8185 - val_loss: 0.7532 - val_acc: 0.6904\n",
      "Epoch 37/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5009 - acc: 0.8191 - val_loss: 0.7564 - val_acc: 0.6896\n",
      "Epoch 38/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.5002 - acc: 0.8196 - val_loss: 0.7573 - val_acc: 0.6896\n",
      "Epoch 39/60\n",
      "6639676/6639676 [==============================] - 110s 17us/step - loss: 0.4992 - acc: 0.8201 - val_loss: 0.7583 - val_acc: 0.6901\n",
      "Epoch 40/60\n",
      "6639676/6639676 [==============================] - 110s 17us/step - loss: 0.4984 - acc: 0.8207 - val_loss: 0.7601 - val_acc: 0.6896\n",
      "Epoch 41/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4975 - acc: 0.8211 - val_loss: 0.7620 - val_acc: 0.6891\n",
      "Epoch 42/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.4966 - acc: 0.8217 - val_loss: 0.7650 - val_acc: 0.6881\n",
      "Epoch 43/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4957 - acc: 0.8222 - val_loss: 0.7653 - val_acc: 0.6885\n",
      "Epoch 44/60\n",
      "6639676/6639676 [==============================] - 110s 16us/step - loss: 0.4949 - acc: 0.8225 - val_loss: 0.7672 - val_acc: 0.6890\n",
      "Epoch 45/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4938 - acc: 0.8232 - val_loss: 0.7694 - val_acc: 0.6881\n",
      "Epoch 46/60\n",
      "6639676/6639676 [==============================] - 112s 17us/step - loss: 0.4930 - acc: 0.8236 - val_loss: 0.7732 - val_acc: 0.6878\n",
      "Epoch 47/60\n",
      "6639676/6639676 [==============================] - 115s 17us/step - loss: 0.4921 - acc: 0.8243 - val_loss: 0.7743 - val_acc: 0.6874\n",
      "Epoch 48/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.4911 - acc: 0.8246 - val_loss: 0.7773 - val_acc: 0.6871\n",
      "Epoch 49/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.4903 - acc: 0.8252 - val_loss: 0.7777 - val_acc: 0.6874\n",
      "Epoch 50/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4895 - acc: 0.8256 - val_loss: 0.7790 - val_acc: 0.6871\n",
      "Epoch 51/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4886 - acc: 0.8259 - val_loss: 0.7811 - val_acc: 0.6871\n",
      "Epoch 52/60\n",
      "6639676/6639676 [==============================] - 110s 17us/step - loss: 0.4880 - acc: 0.8262 - val_loss: 0.7825 - val_acc: 0.6865\n",
      "Epoch 53/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4871 - acc: 0.8268 - val_loss: 0.7850 - val_acc: 0.6871\n",
      "Epoch 54/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4864 - acc: 0.8270 - val_loss: 0.7859 - val_acc: 0.6869\n",
      "Epoch 55/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.4856 - acc: 0.8273 - val_loss: 0.7883 - val_acc: 0.6864\n",
      "Epoch 56/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4850 - acc: 0.8277 - val_loss: 0.7904 - val_acc: 0.6860\n",
      "Epoch 57/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.4844 - acc: 0.8279 - val_loss: 0.7910 - val_acc: 0.6863\n",
      "Epoch 58/60\n",
      "6639676/6639676 [==============================] - 108s 16us/step - loss: 0.4838 - acc: 0.8282 - val_loss: 0.7942 - val_acc: 0.6856\n",
      "Epoch 59/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4833 - acc: 0.8284 - val_loss: 0.7942 - val_acc: 0.6862\n",
      "Epoch 60/60\n",
      "6639676/6639676 [==============================] - 109s 16us/step - loss: 0.4828 - acc: 0.8288 - val_loss: 0.7966 - val_acc: 0.6866\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "mem = mem_model()\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5) # early stop if no val acc improvement for 5 epochs\n",
    "mem_path = '../model/keras/2_mem_model.h5'\n",
    "# save best model\n",
    "model_checkpoint = ModelCheckpoint(mem_path, save_best_only=True, \\\n",
    "        save_weights_only=True)\n",
    "\n",
    "mem.summary()\n",
    "hist = mem.fit(\n",
    "    [X_trn['msno'], X_trn['song_id']], X_trn['target'],\n",
    "    validation_data=([X_val['msno'], X_val['song_id']], X_val['target']), \n",
    "    epochs=30, batch_size=32768, shuffle=True,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "mem.load_weights(mem_path) # load the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce memorization prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772581301868\n",
      "0.802930766793\n",
      "0.771886427379\n",
      "2556790/2556790 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "def mem_validate(model, X):\n",
    "    preds_val = model.predict([X['msno'], X['song_id']], batch_size=32768)\n",
    "    val_auc = roc_auc_score(X['target'], preds_val)\n",
    "    print(val_auc)\n",
    "    return val_auc\n",
    "\n",
    "def mem_produce(model, val_auc):\n",
    "    preds_test = mem.predict([df_test['msno'], df_test['song_id']], batch_size=32768, verbose=1)\n",
    "    sub = pd.DataFrame({'id': df_test['id'], 'target': preds_test.ravel()})\n",
    "    sub.to_csv('../result/sub_' + time.strftime(\"%Y-%m-%d_%H_%M_%S\") + '_%.5f.csv.gz' %(val_auc), \n",
    "               compression = 'gzip', index=False)\n",
    "\n",
    "# print out the validation score\n",
    "val_auc = mem_validate(mem, X_val)\n",
    "mem_validate(mem, X_trn)\n",
    "mem_validate(mem, X_last)\n",
    "\n",
    "# produce output for Kaggle submission\n",
    "mem_produce(mem, val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train generalization DNN\n",
    "to reuse the model layers, use code like `model.layers[0].get_weights()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source_system_tab',\n",
       " 'source_screen_name',\n",
       " 'source_type',\n",
       " 'genre_ids',\n",
       " 'artist_name',\n",
       " 'composer',\n",
       " 'lyricist',\n",
       " 'language',\n",
       " 'city',\n",
       " 'gender',\n",
       " 'registered_via']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAW_CATEGORICAL = CATEGORICAL features without user ids (msno) and song ids\n",
    "RAW_CATEGORICAL = CATEGORICAL.copy()\n",
    "RAW_CATEGORICAL.remove('msno')\n",
    "RAW_CATEGORICAL.remove('song_id')\n",
    "RAW_CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(mem_model):\n",
    "    global cat\n",
    "    cat = RAW_CATEGORICAL\n",
    "    input_layers = dict()\n",
    "    embed_layers = dict()\n",
    "    for col in cat:\n",
    "        # embed the categorical features\n",
    "        vocab_size = int(max(df_train[col].max(), df_test[col].max()) + 1)\n",
    "        embed_size = np.power(2, int(np.ceil(np.log2(np.log2(vocab_size)))))\n",
    "        print('%20s\\tvocab: %8d, embed: %4d' % (col, vocab_size, embed_size))\n",
    "        embed_layers[col] = Embedding(\n",
    "            input_dim = vocab_size,\n",
    "            output_dim = embed_size,\n",
    "            embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer = l2(1e-4),\n",
    "            input_length = 1,\n",
    "            name = col+'_embed',\n",
    "            trainable=True)\n",
    "        \n",
    "        input_layers[col] = Input(shape=(1,), name=col+'_input')\n",
    "        embed_layers[col] = embed_layers[col](input_layers[col])\n",
    "        embed_layers[col] = Reshape((embed_size,))(embed_layers[col])\n",
    "    n_num = len(NUMERICAL)\n",
    "    numerical_input = Input(shape=(n_num,), name='numerical_input')\n",
    "    # input features concatenates the outputs of embedding layers and numerical features\n",
    "    preds = concatenate([embed_layers[col] for col in cat] + [numerical_input])\n",
    "    \n",
    "    # generalization layers, from features to latent vectors\n",
    "    preds = Dense(128, activation='relu', name='gen_dense1')(preds)\n",
    "    # dropout\n",
    "    preds = Dropout(0.5, name='gen_dropout')(preds)\n",
    "    # output layer: just linear\n",
    "    preds = Dense(128, name='gen_dense3')(preds) \n",
    "    latent_user = Lambda(lambda x: x[:, :64], name='latent_user')(preds)\n",
    "    latent_song = Lambda(lambda x: x[:, 64:], name='latent_song')(preds)\n",
    "    preds = dot([latent_song, latent_user], axes=1)\n",
    "    preds = concatenate([latent_user, latent_song, preds], name='gen_latent')\n",
    "    \n",
    "    ############################################\n",
    "    ## inheritate layers from memorization model\n",
    "    ############################################\n",
    "    mem_layer_trainable = False # fixed\n",
    "    # mem_layer_trainable = True # not fixed\n",
    "    \n",
    "    layer = mem_model.get_layer('mem_dense1')\n",
    "    layer.trainable = mem_layer_trainable\n",
    "    preds = layer(preds)\n",
    "    layer = mem_model.get_layer('mem_dropout1')\n",
    "    layer.trainable = mem_layer_trainable\n",
    "    preds = layer(preds)\n",
    "    layer = mem_model.get_layer('mem_output')\n",
    "    layer.trainable = mem_layer_trainable\n",
    "    preds = layer(preds)\n",
    "    \n",
    "    input_list = [input_layers[col] for col in cat] + [numerical_input]\n",
    "\n",
    "    model = Model(inputs=input_list, outputs=preds)\n",
    "    opt = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def gen_input(X):\n",
    "    # generate feature matrix from the data frame\n",
    "    return [X[col] for col in cat] + [X.loc[:, NUMERICAL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source_system_tab\tvocab:       10, embed:    4\n",
      "  source_screen_name\tvocab:       22, embed:    8\n",
      "         source_type\tvocab:       13, embed:    4\n",
      "           genre_ids\tvocab:      609, embed:   16\n",
      "         artist_name\tvocab:    46373, embed:   16\n",
      "            composer\tvocab:    86438, embed:   32\n",
      "            lyricist\tvocab:    37876, embed:   16\n",
      "            language\tvocab:       11, embed:    4\n",
      "                city\tvocab:       21, embed:    8\n",
      "              gender\tvocab:        3, embed:    2\n",
      "      registered_via\tvocab:        6, embed:    4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "source_system_tab_input (InputL (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_screen_name_input (Input (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_type_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "genre_ids_input (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "artist_name_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "composer_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lyricist_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "language_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "city_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "registered_via_input (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_system_tab_embed (Embedd (None, 1, 4)         40          source_system_tab_input[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "source_screen_name_embed (Embed (None, 1, 8)         176         source_screen_name_input[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "source_type_embed (Embedding)   (None, 1, 4)         52          source_type_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "genre_ids_embed (Embedding)     (None, 1, 16)        9744        genre_ids_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "artist_name_embed (Embedding)   (None, 1, 16)        741968      artist_name_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "composer_embed (Embedding)      (None, 1, 32)        2766016     composer_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lyricist_embed (Embedding)      (None, 1, 16)        606016      lyricist_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "language_embed (Embedding)      (None, 1, 4)         44          language_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "city_embed (Embedding)          (None, 1, 8)         168         city_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gender_embed (Embedding)        (None, 1, 2)         6           gender_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "registered_via_embed (Embedding (None, 1, 4)         24          registered_via_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_136 (Reshape)           (None, 4)            0           source_system_tab_embed[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_137 (Reshape)           (None, 8)            0           source_screen_name_embed[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_138 (Reshape)           (None, 4)            0           source_type_embed[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_139 (Reshape)           (None, 16)           0           genre_ids_embed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_140 (Reshape)           (None, 16)           0           artist_name_embed[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_141 (Reshape)           (None, 32)           0           composer_embed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_142 (Reshape)           (None, 16)           0           lyricist_embed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_143 (Reshape)           (None, 4)            0           language_embed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_144 (Reshape)           (None, 8)            0           city_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_145 (Reshape)           (None, 2)            0           gender_embed[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_146 (Reshape)           (None, 4)            0           registered_via_embed[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "numerical_input (InputLayer)    (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 136)          0           reshape_136[0][0]                \n",
      "                                                                 reshape_137[0][0]                \n",
      "                                                                 reshape_138[0][0]                \n",
      "                                                                 reshape_139[0][0]                \n",
      "                                                                 reshape_140[0][0]                \n",
      "                                                                 reshape_141[0][0]                \n",
      "                                                                 reshape_142[0][0]                \n",
      "                                                                 reshape_143[0][0]                \n",
      "                                                                 reshape_144[0][0]                \n",
      "                                                                 reshape_145[0][0]                \n",
      "                                                                 reshape_146[0][0]                \n",
      "                                                                 numerical_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_dense1 (Dense)              (None, 128)          17536       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gen_dropout (Dropout)           (None, 128)          0           gen_dense1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gen_dense3 (Dense)              (None, 128)          16512       gen_dropout[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "latent_user (Lambda)            (None, 64)           0           gen_dense3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "latent_song (Lambda)            (None, 64)           0           gen_dense3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 1)            0           latent_song[0][0]                \n",
      "                                                                 latent_user[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gen_latent (Concatenate)        (None, 129)          0           latent_user[0][0]                \n",
      "                                                                 latent_song[0][0]                \n",
      "                                                                 dot_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mem_dense1 (Dense)              (None, 128)          16640       gen_latent[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mem_output (Dense)              (None, 1)            129         mem_dense1[2][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,175,071\n",
      "Trainable params: 4,175,071\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen = gen_model(mem)\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6639676 samples, validate on 737742 samples\n",
      "Epoch 1/100\n",
      "6639676/6639676 [==============================] - 86s 13us/step - loss: 0.9153 - acc: 0.5934 - val_loss: 0.6362 - val_acc: 0.6465\n",
      "Epoch 2/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6363 - acc: 0.6469 - val_loss: 0.6326 - val_acc: 0.6499\n",
      "Epoch 3/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6336 - acc: 0.6494 - val_loss: 0.6318 - val_acc: 0.6509\n",
      "Epoch 4/100\n",
      "6639676/6639676 [==============================] - 83s 12us/step - loss: 0.6322 - acc: 0.6505 - val_loss: 0.6302 - val_acc: 0.6524\n",
      "Epoch 5/100\n",
      "6639676/6639676 [==============================] - 83s 13us/step - loss: 0.6312 - acc: 0.6515 - val_loss: 0.6297 - val_acc: 0.6532\n",
      "Epoch 6/100\n",
      "6639676/6639676 [==============================] - 83s 13us/step - loss: 0.6304 - acc: 0.6524 - val_loss: 0.6289 - val_acc: 0.6538\n",
      "Epoch 7/100\n",
      "6639676/6639676 [==============================] - 92s 14us/step - loss: 0.6298 - acc: 0.6529 - val_loss: 0.6280 - val_acc: 0.6545\n",
      "Epoch 8/100\n",
      "6639676/6639676 [==============================] - 89s 13us/step - loss: 0.6291 - acc: 0.6536 - val_loss: 0.6290 - val_acc: 0.6544\n",
      "Epoch 9/100\n",
      "6639676/6639676 [==============================] - 83s 13us/step - loss: 0.6287 - acc: 0.6539 - val_loss: 0.6280 - val_acc: 0.6552\n",
      "Epoch 10/100\n",
      "6639676/6639676 [==============================] - 86s 13us/step - loss: 0.6282 - acc: 0.6545 - val_loss: 0.6269 - val_acc: 0.6557\n",
      "Epoch 11/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6277 - acc: 0.6551 - val_loss: 0.6268 - val_acc: 0.6567\n",
      "Epoch 12/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6273 - acc: 0.6553 - val_loss: 0.6264 - val_acc: 0.6562\n",
      "Epoch 13/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6270 - acc: 0.6559 - val_loss: 0.6258 - val_acc: 0.6573\n",
      "Epoch 14/100\n",
      "6639676/6639676 [==============================] - 86s 13us/step - loss: 0.6266 - acc: 0.6563 - val_loss: 0.6256 - val_acc: 0.6580\n",
      "Epoch 15/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6263 - acc: 0.6566 - val_loss: 0.6248 - val_acc: 0.6579\n",
      "Epoch 16/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6260 - acc: 0.6572 - val_loss: 0.6250 - val_acc: 0.6583\n",
      "Epoch 17/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6257 - acc: 0.6574 - val_loss: 0.6247 - val_acc: 0.6589\n",
      "Epoch 18/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6254 - acc: 0.6578 - val_loss: 0.6247 - val_acc: 0.6581\n",
      "Epoch 19/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6252 - acc: 0.6583 - val_loss: 0.6257 - val_acc: 0.6591\n",
      "Epoch 20/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6249 - acc: 0.6583 - val_loss: 0.6255 - val_acc: 0.6592\n",
      "Epoch 21/100\n",
      "6639676/6639676 [==============================] - 83s 13us/step - loss: 0.6248 - acc: 0.6587 - val_loss: 0.6247 - val_acc: 0.6597\n",
      "Epoch 22/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6246 - acc: 0.6589 - val_loss: 0.6235 - val_acc: 0.6600\n",
      "Epoch 23/100\n",
      "6639676/6639676 [==============================] - 86s 13us/step - loss: 0.6244 - acc: 0.6592 - val_loss: 0.6240 - val_acc: 0.6603\n",
      "Epoch 24/100\n",
      "6639676/6639676 [==============================] - 87s 13us/step - loss: 0.6242 - acc: 0.6594 - val_loss: 0.6245 - val_acc: 0.6603\n",
      "Epoch 25/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6240 - acc: 0.6596 - val_loss: 0.6245 - val_acc: 0.6605\n",
      "Epoch 26/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6239 - acc: 0.6597 - val_loss: 0.6243 - val_acc: 0.6604\n",
      "Epoch 27/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6238 - acc: 0.6600 - val_loss: 0.6238 - val_acc: 0.6607\n",
      "Epoch 28/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6236 - acc: 0.6600 - val_loss: 0.6239 - val_acc: 0.6604\n",
      "Epoch 29/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6235 - acc: 0.6603 - val_loss: 0.6242 - val_acc: 0.6606\n",
      "Epoch 30/100\n",
      "6639676/6639676 [==============================] - 82s 12us/step - loss: 0.6234 - acc: 0.6602 - val_loss: 0.6251 - val_acc: 0.6598\n",
      "Epoch 31/100\n",
      "6639676/6639676 [==============================] - 82s 12us/step - loss: 0.6233 - acc: 0.6604 - val_loss: 0.6232 - val_acc: 0.6615\n",
      "Epoch 32/100\n",
      "6639676/6639676 [==============================] - 83s 12us/step - loss: 0.6232 - acc: 0.6606 - val_loss: 0.6242 - val_acc: 0.6613\n",
      "Epoch 33/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6230 - acc: 0.6608 - val_loss: 0.6236 - val_acc: 0.6614\n",
      "Epoch 34/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6229 - acc: 0.6610 - val_loss: 0.6235 - val_acc: 0.6618\n",
      "Epoch 35/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6229 - acc: 0.6610 - val_loss: 0.6233 - val_acc: 0.6620\n",
      "Epoch 36/100\n",
      "6639676/6639676 [==============================] - 83s 13us/step - loss: 0.6227 - acc: 0.6611 - val_loss: 0.6239 - val_acc: 0.6619\n",
      "Epoch 37/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6228 - acc: 0.6610 - val_loss: 0.6235 - val_acc: 0.6612\n",
      "Epoch 38/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6226 - acc: 0.6614 - val_loss: 0.6245 - val_acc: 0.6617\n",
      "Epoch 39/100\n",
      "6639676/6639676 [==============================] - 86s 13us/step - loss: 0.6225 - acc: 0.6614 - val_loss: 0.6234 - val_acc: 0.6622\n",
      "Epoch 40/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6225 - acc: 0.6616 - val_loss: 0.6235 - val_acc: 0.6613\n",
      "Epoch 41/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6224 - acc: 0.6617 - val_loss: 0.6239 - val_acc: 0.6622\n",
      "Epoch 42/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6223 - acc: 0.6619 - val_loss: 0.6233 - val_acc: 0.6622\n",
      "Epoch 43/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6222 - acc: 0.6619 - val_loss: 0.6227 - val_acc: 0.6625\n",
      "Epoch 44/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6221 - acc: 0.6619 - val_loss: 0.6242 - val_acc: 0.6625\n",
      "Epoch 45/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6221 - acc: 0.6620 - val_loss: 0.6234 - val_acc: 0.6627\n",
      "Epoch 46/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6220 - acc: 0.6622 - val_loss: 0.6240 - val_acc: 0.6613\n",
      "Epoch 47/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6219 - acc: 0.6621 - val_loss: 0.6241 - val_acc: 0.6627\n",
      "Epoch 48/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6218 - acc: 0.6623 - val_loss: 0.6231 - val_acc: 0.6626\n",
      "Epoch 49/100\n",
      "6639676/6639676 [==============================] - 86s 13us/step - loss: 0.6218 - acc: 0.6623 - val_loss: 0.6247 - val_acc: 0.6628\n",
      "Epoch 50/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6218 - acc: 0.6624 - val_loss: 0.6248 - val_acc: 0.6631\n",
      "Epoch 51/100\n",
      "6639676/6639676 [==============================] - 86s 13us/step - loss: 0.6216 - acc: 0.6625 - val_loss: 0.6243 - val_acc: 0.6627\n",
      "Epoch 52/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6217 - acc: 0.6626 - val_loss: 0.6243 - val_acc: 0.6629\n",
      "Epoch 53/100\n",
      "6639676/6639676 [==============================] - 84s 13us/step - loss: 0.6216 - acc: 0.6626 - val_loss: 0.6234 - val_acc: 0.6627\n",
      "Epoch 54/100\n",
      "6639676/6639676 [==============================] - 87s 13us/step - loss: 0.6216 - acc: 0.6626 - val_loss: 0.6235 - val_acc: 0.6628\n",
      "Epoch 55/100\n",
      "6639676/6639676 [==============================] - 85s 13us/step - loss: 0.6216 - acc: 0.6627 - val_loss: 0.6246 - val_acc: 0.6620\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5) # early stop\n",
    "gen_path = '../model/keras/gen_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(gen_path, save_best_only=True, save_weights_only=True) # save best models\n",
    "\n",
    "# training\n",
    "hist = gen.fit(\n",
    "    gen_input(X_trn), X_trn['target'],\n",
    "    validation_data=(gen_input(X_val), X_val['target']), \n",
    "    epochs=100, batch_size=32768, shuffle=True,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "# load the best model\n",
    "gen.load_weights(gen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_validate(model, X):\n",
    "    preds_val = model.predict(gen_input(X), batch_size=32768)\n",
    "    val_auc = roc_auc_score(X['target'], preds_val)\n",
    "    print(val_auc)\n",
    "    return val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_produce(model, val_auc):\n",
    "    preds_test = model.predict(gen_input(df_test), batch_size=32768, verbose=1)\n",
    "    sub = pd.DataFrame({'id': df_test['id'], 'target': preds_test.ravel()})\n",
    "    sub.to_csv('../result/sub_' + time.strftime(\"%Y-%m-%d_%H_%M_%S\") + '_%.5f.csv.gz' %(val_auc), \n",
    "               compression = 'gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718293225796\n",
      "0.674239553462\n",
      "2556790/2556790 [==============================] - 9s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# validate auc\n",
    "val_auc = gen_validate(gen, X_val)\n",
    "gen_validate(gen, X_last)\n",
    "\n",
    "# generate output for Kaggle submission\n",
    "gen_produce(gen, val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Other Experiments Related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = RAW_CATEGORICAL # without uid & sid\n",
    "# cat = CATEGORICAL # with uid & sid\n",
    "\n",
    "def dnn_model():\n",
    "    input_layers = dict()\n",
    "    embed_layers = dict()\n",
    "    for col in cat:\n",
    "        # embedding layers for categorical features\n",
    "        vocab_size = int(max(df_train[col].max(), df_test[col].max()) + 1)\n",
    "        embed_size = np.power(2, int(np.ceil(np.log2(np.log2(vocab_size)))))\n",
    "        print('%20s\\tvocab: %8d, embed: %4d' % (col, vocab_size, embed_size))\n",
    "        embed_layers[col] = Embedding(\n",
    "            input_dim = vocab_size,\n",
    "            output_dim = embed_size,\n",
    "            embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer = l2(1e-4),\n",
    "            input_length = 1,\n",
    "            name = col+'_embed',\n",
    "            trainable=True)\n",
    "        \n",
    "        input_layers[col] = Input(shape=(1,), name=col+'_input')\n",
    "        embed_layers[col] = embed_layers[col](input_layers[col])\n",
    "        embed_layers[col] = Reshape((embed_size,))(embed_layers[col])\n",
    "    n_num = len(NUMERICAL)\n",
    "    numerical_input = Input(shape=(n_num,), name='numerical_input')\n",
    "    preds = concatenate([embed_layers[col] for col in cat] + [numerical_input])\n",
    "    \n",
    "    # hidden layers\n",
    "    preds = Dense(128, activation='relu', name='dnn_dense1')(preds)\n",
    "    preds = Dense(64, activation='relu', name='dnn_dense2')(preds)\n",
    "    preds = Dense(32, activation='relu', name='dnn_dense3')(preds)\n",
    "    # dropout\n",
    "    preds = Dropout(0.5)(preds)\n",
    "    # output layer\n",
    "    preds = Dense(1, activation='sigmoid')(preds)\n",
    "    \n",
    "    input_list = [input_layers[col] for col in cat] + [numerical_input]\n",
    "\n",
    "    model = Model(inputs=input_list, outputs=preds)\n",
    "    opt = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def dnn_input(X):\n",
    "    return [X[col] for col in cat] + [X.loc[:, NUMERICAL]]\n",
    "\n",
    "def dnn_validate(model, X):\n",
    "    preds_val = model.predict(dnn_input(X), batch_size=32768)\n",
    "    val_auc = roc_auc_score(X['target'], preds_val)\n",
    "    print(val_auc)\n",
    "    return val_auc\n",
    "\n",
    "def dnn_produce(model, val_auc):\n",
    "    preds_test = model.predict(dnn_input(df_test), batch_size=32768, verbose=1)\n",
    "    sub = pd.DataFrame({'id': df_test['id'], 'target': preds_test.ravel()})\n",
    "    sub.to_csv('../result/sub_dnn_' + time.strftime(\"%Y-%m-%d_%H_%M_%S\") + '_%.5f.csv.gz' %(val_auc), \n",
    "               compression = 'gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source_system_tab\tvocab:       10, embed:    4\n",
      "  source_screen_name\tvocab:       22, embed:    8\n",
      "         source_type\tvocab:       13, embed:    4\n",
      "           genre_ids\tvocab:      609, embed:   16\n",
      "         artist_name\tvocab:    46373, embed:   16\n",
      "            composer\tvocab:    86438, embed:   32\n",
      "            lyricist\tvocab:    37876, embed:   16\n",
      "            language\tvocab:       11, embed:    4\n",
      "                city\tvocab:       21, embed:    8\n",
      "              gender\tvocab:        3, embed:    2\n",
      "      registered_via\tvocab:        6, embed:    4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "source_system_tab_input (InputL (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_screen_name_input (Input (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_type_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "genre_ids_input (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "artist_name_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "composer_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lyricist_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "language_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "city_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "registered_via_input (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_system_tab_embed (Embedd (None, 1, 4)         40          source_system_tab_input[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "source_screen_name_embed (Embed (None, 1, 8)         176         source_screen_name_input[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "source_type_embed (Embedding)   (None, 1, 4)         52          source_type_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "genre_ids_embed (Embedding)     (None, 1, 16)        9744        genre_ids_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "artist_name_embed (Embedding)   (None, 1, 16)        741968      artist_name_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "composer_embed (Embedding)      (None, 1, 32)        2766016     composer_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lyricist_embed (Embedding)      (None, 1, 16)        606016      lyricist_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "language_embed (Embedding)      (None, 1, 4)         44          language_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "city_embed (Embedding)          (None, 1, 8)         168         city_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gender_embed (Embedding)        (None, 1, 2)         6           gender_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "registered_via_embed (Embedding (None, 1, 4)         24          registered_via_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 4)            0           source_system_tab_embed[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 8)            0           source_screen_name_embed[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 4)            0           source_type_embed[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 16)           0           genre_ids_embed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 16)           0           artist_name_embed[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 32)           0           composer_embed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 16)           0           lyricist_embed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 4)            0           language_embed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 8)            0           city_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 2)            0           gender_embed[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 4)            0           registered_via_embed[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "numerical_input (InputLayer)    (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 136)          0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 numerical_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dnn_dense1 (Dense)              (None, 128)          17536       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dnn_dense2 (Dense)              (None, 64)           8256        dnn_dense1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dnn_dense3 (Dense)              (None, 32)           2080        dnn_dense2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dnn_dense3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,152,159\n",
      "Trainable params: 4,152,159\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn = dnn_model()\n",
    "dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6639676 samples, validate on 737742 samples\n",
      "Epoch 1/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.7903 - acc: 0.6370 - val_loss: 0.6351 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "6639676/6639676 [==============================] - 50s 7us/step - loss: 0.6361 - acc: 0.6487 - val_loss: 0.6331 - val_acc: 0.6485\n",
      "Epoch 3/100\n",
      "6639676/6639676 [==============================] - 50s 7us/step - loss: 0.6345 - acc: 0.6499 - val_loss: 0.6296 - val_acc: 0.6511\n",
      "Epoch 4/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6331 - acc: 0.6512 - val_loss: 0.6293 - val_acc: 0.6515\n",
      "Epoch 5/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6319 - acc: 0.6522 - val_loss: 0.6284 - val_acc: 0.6525\n",
      "Epoch 6/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6306 - acc: 0.6534 - val_loss: 0.6262 - val_acc: 0.6542\n",
      "Epoch 7/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6294 - acc: 0.6544 - val_loss: 0.6274 - val_acc: 0.6529\n",
      "Epoch 8/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6282 - acc: 0.6555 - val_loss: 0.6252 - val_acc: 0.6557\n",
      "Epoch 9/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6270 - acc: 0.6569 - val_loss: 0.6238 - val_acc: 0.6561\n",
      "Epoch 10/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6259 - acc: 0.6580 - val_loss: 0.6231 - val_acc: 0.6576\n",
      "Epoch 11/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6247 - acc: 0.6593 - val_loss: 0.6223 - val_acc: 0.6586\n",
      "Epoch 12/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6236 - acc: 0.6604 - val_loss: 0.6204 - val_acc: 0.6599\n",
      "Epoch 13/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6225 - acc: 0.6615 - val_loss: 0.6189 - val_acc: 0.6613\n",
      "Epoch 14/100\n",
      "6639676/6639676 [==============================] - 52s 8us/step - loss: 0.6215 - acc: 0.6627 - val_loss: 0.6181 - val_acc: 0.6616\n",
      "Epoch 15/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6204 - acc: 0.6638 - val_loss: 0.6175 - val_acc: 0.6628\n",
      "Epoch 16/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6195 - acc: 0.6648 - val_loss: 0.6179 - val_acc: 0.6629\n",
      "Epoch 17/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6185 - acc: 0.6657 - val_loss: 0.6172 - val_acc: 0.6633\n",
      "Epoch 18/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6176 - acc: 0.6667 - val_loss: 0.6163 - val_acc: 0.6638\n",
      "Epoch 19/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6168 - acc: 0.6672 - val_loss: 0.6148 - val_acc: 0.6656\n",
      "Epoch 20/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6159 - acc: 0.6680 - val_loss: 0.6138 - val_acc: 0.6664\n",
      "Epoch 21/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6151 - acc: 0.6689 - val_loss: 0.6152 - val_acc: 0.6650\n",
      "Epoch 22/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6145 - acc: 0.6694 - val_loss: 0.6130 - val_acc: 0.6670\n",
      "Epoch 23/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6138 - acc: 0.6702 - val_loss: 0.6152 - val_acc: 0.6665\n",
      "Epoch 24/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6131 - acc: 0.6707 - val_loss: 0.6124 - val_acc: 0.6683\n",
      "Epoch 25/100\n",
      "6639676/6639676 [==============================] - 50s 7us/step - loss: 0.6125 - acc: 0.6713 - val_loss: 0.6122 - val_acc: 0.6687\n",
      "Epoch 26/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6118 - acc: 0.6720 - val_loss: 0.6141 - val_acc: 0.6661\n",
      "Epoch 27/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6112 - acc: 0.6725 - val_loss: 0.6132 - val_acc: 0.6668\n",
      "Epoch 28/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6106 - acc: 0.6729 - val_loss: 0.6115 - val_acc: 0.6698\n",
      "Epoch 29/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6102 - acc: 0.6735 - val_loss: 0.6112 - val_acc: 0.6692\n",
      "Epoch 30/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6096 - acc: 0.6739 - val_loss: 0.6134 - val_acc: 0.6664\n",
      "Epoch 31/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6092 - acc: 0.6742 - val_loss: 0.6113 - val_acc: 0.6702\n",
      "Epoch 32/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6087 - acc: 0.6749 - val_loss: 0.6147 - val_acc: 0.6649\n",
      "Epoch 33/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6083 - acc: 0.6751 - val_loss: 0.6106 - val_acc: 0.6696\n",
      "Epoch 34/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6078 - acc: 0.6754 - val_loss: 0.6092 - val_acc: 0.6714\n",
      "Epoch 35/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6073 - acc: 0.6758 - val_loss: 0.6112 - val_acc: 0.6693\n",
      "Epoch 36/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6069 - acc: 0.6761 - val_loss: 0.6113 - val_acc: 0.6687\n",
      "Epoch 37/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6065 - acc: 0.6767 - val_loss: 0.6096 - val_acc: 0.6718\n",
      "Epoch 38/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6061 - acc: 0.6769 - val_loss: 0.6106 - val_acc: 0.6695\n",
      "Epoch 39/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6058 - acc: 0.6772 - val_loss: 0.6104 - val_acc: 0.6692\n",
      "Epoch 40/100\n",
      "6639676/6639676 [==============================] - 50s 8us/step - loss: 0.6054 - acc: 0.6775 - val_loss: 0.6106 - val_acc: 0.6700\n",
      "Epoch 41/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6050 - acc: 0.6777 - val_loss: 0.6128 - val_acc: 0.6705\n",
      "Epoch 42/100\n",
      "6639676/6639676 [==============================] - 51s 8us/step - loss: 0.6047 - acc: 0.6781 - val_loss: 0.6107 - val_acc: 0.6717\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5) # early stop\n",
    "dnn_path = '../model/keras/dnn_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(dnn_path, save_best_only=True, save_weights_only=True) # save the best model\n",
    "# training\n",
    "hist = dnn.fit(\n",
    "    dnn_input(X_trn), X_trn['target'],\n",
    "    validation_data=(dnn_input(X_val), X_val['target']), \n",
    "    epochs=100, batch_size=32768, shuffle=True,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "# load the best model\n",
    "dnn.load_weights(dnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735858533144\n",
      "0.703385242235\n",
      "2556790/2556790 [==============================] - 6s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "val_auc = dnn_validate(dnn, X_val)\n",
    "dnn_validate(dnn, X_last)\n",
    "# generate the output for Kaggle submission\n",
    "dnn_produce(dnn, val_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
