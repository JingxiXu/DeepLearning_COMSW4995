{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import glob\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions, DO NOT modify this\n",
    "\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imread(path)\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)\n",
    "        \n",
    "# Functions to load data, DO NOT change these\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    y_one_hot[y] = 1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = get_img_array(f).astype(np.float)\n",
    "#         img_arr = img_arr.flatten() / 255.0\n",
    "        images.append(img_arr)\n",
    "    # X = np.column_stack(images)\n",
    "    X = np.stack(images, axis=0)\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + 'train'\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "Loaded 10000/50000\n",
      "Loaded 20000/50000\n",
      "Loaded 30000/50000\n",
      "Loaded 40000/50000\n",
      "Loaded 50000/50000\n",
      "Loaded 10000/10000\n",
      "Data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_root_path = 'cifar10-hw/'\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "print('Data loading done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group's helper function\n",
    "def split(X, y, val_size):\n",
    "    '''\n",
    "    split the data into training and validation set\n",
    "    '''\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    test_num = int(val_size * X.shape[0])\n",
    "    return X[indices[test_num:]], X[indices[:test_num]], y[indices[test_num:]], y[indices[:test_num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3)\n",
      "(5000, 32, 32, 3)\n",
      "(45000,)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_val, y_trn, y_val = split(X_train, y_train, val_size=0.1)\n",
    "print(X_trn.shape)\n",
    "print(X_val.shape)\n",
    "print(y_trn.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GLobal value\n",
    "H, W, T = 32, 32, 10 # height/width of images, number of classes of images\n",
    "cnns = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self, model_fn, trainer, global_step=None):\n",
    "        if global_step is None:\n",
    "            tf.reset_default_graph()\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "        self.X = tf.placeholder(tf.float32, [None, H, W, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "        self.is_training = tf.placeholder(tf.bool)\n",
    "        logit, loss = model_fn(self.X, self.Y, self.is_training)\n",
    "        # https://stackoverflow.com/a/43285333\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(extra_update_ops):\n",
    "            train_op = trainer.minimize(loss, global_step=global_step)\n",
    "        # train_op = trainer.minimize(loss)\n",
    "        # Accuracy\n",
    "        correct = tf.equal(tf.argmax(logit, 1), self.Y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        self.variables = {\n",
    "            'train': [loss, correct, train_op],\n",
    "            'validate': [loss, correct, accuracy]}\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def batch_gen(self, Xd, Yd, batch_size, shuffle=True):\n",
    "        indicies = np.arange(Xd.shape[0])\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indicies)\n",
    "        for i in range(int(math.ceil(Xd.shape[0] / batch_size))):\n",
    "            start_idx = (i * batch_size) % Xd.shape[0]\n",
    "            idx = indicies[start_idx:start_idx + batch_size]\n",
    "            yield Xd[idx, :], Yd[idx]\n",
    "\n",
    "    def run(self, Xd, Yd, epochs, batch_size, print_every, plot_losses, status):\n",
    "        iter_cnt = 0\n",
    "        for e in range(epochs):\n",
    "            correct = 0\n",
    "            losses = []\n",
    "            for Xb, Yb in self.batch_gen(Xd, Yd, batch_size, shuffle = True):\n",
    "                feed_dict = {self.X: Xb, self.Y: Yb, self.is_training: status=='train'}\n",
    "                loss, corr, _ = self.sess.run(self.variables[status], feed_dict = feed_dict)\n",
    "                losses.append(loss)\n",
    "                correct += np.sum(corr)\n",
    "                if status == 'train' and iter_cnt % print_every == 0:\n",
    "                    print(\"{} Iter {}: batch trn loss = {:.3f}, accuracy = {:.3f}\".format(\n",
    "                        datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        iter_cnt,\n",
    "                        loss,\n",
    "                        np.mean(corr),\n",
    "                    ))\n",
    "                iter_cnt += 1\n",
    "            epoch_loss = np.mean(losses)\n",
    "            epoch_accuracy = correct / Xd.shape[0]\n",
    "            print(\"Epoch {}: mean loss = {:.3f}, accuracy = {:.3f}\".format(\n",
    "                e, epoch_loss, epoch_accuracy))\n",
    "            if plot_losses:\n",
    "                plt.plot(losses)\n",
    "                plt.grid(True)\n",
    "                plt.title('Epoch {} Mean Loss'.format(e+1))\n",
    "                plt.xlabel('minibatch number')\n",
    "                plt.ylabel('minibatch mean loss')\n",
    "                plt.show()\n",
    "        return epoch_loss, epoch_accuracy\n",
    "\n",
    "    def train(self, Xd, Yd, epochs=1, batch_size=50, print_every=100, plot_losses=False):\n",
    "        return self.run(Xd, Yd, epochs, batch_size, print_every, plot_losses, status='train')\n",
    "            \n",
    "    def validate(self, Xd, Yd, epochs=1, batch_size=50, print_every=100, plot_losses=False):\n",
    "        return self.run(Xd, Yd, epochs, batch_size, print_every, plot_losses, status='validate')\n",
    "    \n",
    "    def predict(self, Xd):\n",
    "        feed_dict = {self.X: Xd, self.is_training: False}\n",
    "        variables = [self.Y]\n",
    "        Yp = self.sess.run(variables, feed_dict = feed_dict)\n",
    "        return Yp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0102] witness\n",
    "- base (0101): add winess, batch_size to 100, with dropout 0.5 (dropout is not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def witness(raw_images):\n",
    "    images = np.empty_like(raw_images)\n",
    "    np.copyto(images, raw_images)\n",
    "    for i in range(images.shape[0]):\n",
    "        old = images[i]\n",
    "        new = (old - np.mean(old)) / np.std(old)\n",
    "        images[i, :, :, :] = new\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3136\n"
     ]
    }
   ],
   "source": [
    "def model_fn(layer_input, labels, is_training):\n",
    "    reg_scale= 0.1\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=reg_scale)\n",
    "    # initializer = tf.contrib.layers.xavier_initializer()\n",
    "    initializer = None\n",
    "    h, w = H, W\n",
    "    # conv - bn - max_pool\n",
    "    F1 = 64\n",
    "    P1, S1 = 3, 2 # pool_size, strides\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=layer_input, filters=F1, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, training=is_training,\n",
    "        beta_regularizer=regularizer, gamma_regularizer=regularizer)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=P1, strides=S1)\n",
    "    h = math.floor((h - P1 + S1) / S1)\n",
    "    w = math.floor((w - P1 + S1) / S1)\n",
    "    # conv - bn - max_pool\n",
    "    F2 = 64\n",
    "    P2, S2 = 3, 2 # pool_size, strides\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=layer, filters=F2, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, training=is_training,\n",
    "        beta_regularizer=regularizer, gamma_regularizer=regularizer)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=P2, strides=S2)\n",
    "    h = math.floor((h - P2 + S2) / S2)\n",
    "    w = math.floor((w - P2 + S2) / S2)\n",
    "    # dense1 - bn - dropout - fc - softmax\n",
    "    flat_size = F2 * h * w\n",
    "    print(flat_size)\n",
    "    layer = tf.reshape(layer, [-1, flat_size])\n",
    "    layer = tf.layers.dense(\n",
    "        inputs=layer, units=1024, activation=tf.nn.relu,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, training=is_training,\n",
    "        beta_regularizer=regularizer, gamma_regularizer=regularizer)\n",
    "    layer = tf.layers.dropout(inputs=layer, rate=0.5)\n",
    "    # no activation here for logit, as it will be calculated in loss\n",
    "    logit = tf.layers.dense(\n",
    "        inputs=layer, units=T, activation=None,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int64), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logit)\n",
    "    return logit, loss\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "cnn = CNN(model_fn, trainer)\n",
    "cnns['0102'] = cnn\n",
    "\n",
    "m_X_trn = witness(X_trn)\n",
    "m_X_val = witness(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 11:20:30 Iter 0: batch trn loss = 3.250, accuracy = 0.070\n",
      "2017-10-29 11:21:40 Iter 100: batch trn loss = 1.315, accuracy = 0.530\n",
      "2017-10-29 11:22:51 Iter 200: batch trn loss = 1.346, accuracy = 0.510\n",
      "2017-10-29 11:23:57 Iter 300: batch trn loss = 1.078, accuracy = 0.640\n",
      "2017-10-29 11:25:05 Iter 400: batch trn loss = 1.171, accuracy = 0.620\n",
      "Epoch 0: mean loss = 1.329, accuracy = 0.550\n",
      "2017-10-29 11:26:12 Iter 500: batch trn loss = 0.779, accuracy = 0.720\n",
      "2017-10-29 11:27:19 Iter 600: batch trn loss = 1.067, accuracy = 0.580\n",
      "2017-10-29 11:28:26 Iter 700: batch trn loss = 0.834, accuracy = 0.690\n",
      "2017-10-29 11:29:33 Iter 800: batch trn loss = 0.763, accuracy = 0.760\n",
      "Epoch 1: mean loss = 0.843, accuracy = 0.710\n",
      "2017-10-29 11:30:40 Iter 900: batch trn loss = 0.543, accuracy = 0.790\n",
      "2017-10-29 11:31:47 Iter 1000: batch trn loss = 0.804, accuracy = 0.720\n",
      "2017-10-29 11:32:54 Iter 1100: batch trn loss = 0.628, accuracy = 0.760\n",
      "2017-10-29 11:34:02 Iter 1200: batch trn loss = 0.620, accuracy = 0.710\n",
      "2017-10-29 11:35:07 Iter 1300: batch trn loss = 0.711, accuracy = 0.740\n",
      "Epoch 2: mean loss = 0.662, accuracy = 0.773\n",
      "2017-10-29 11:36:18 Iter 1400: batch trn loss = 0.481, accuracy = 0.860\n",
      "2017-10-29 11:37:25 Iter 1500: batch trn loss = 0.495, accuracy = 0.800\n",
      "2017-10-29 11:38:32 Iter 1600: batch trn loss = 0.645, accuracy = 0.790\n",
      "2017-10-29 11:39:37 Iter 1700: batch trn loss = 0.549, accuracy = 0.820\n",
      "Epoch 3: mean loss = 0.534, accuracy = 0.817\n",
      "2017-10-29 11:40:42 Iter 1800: batch trn loss = 0.490, accuracy = 0.830\n",
      "2017-10-29 11:41:47 Iter 1900: batch trn loss = 0.426, accuracy = 0.890\n",
      "2017-10-29 11:42:58 Iter 2000: batch trn loss = 0.407, accuracy = 0.860\n",
      "2017-10-29 11:44:04 Iter 2100: batch trn loss = 0.459, accuracy = 0.820\n",
      "2017-10-29 11:45:09 Iter 2200: batch trn loss = 0.461, accuracy = 0.860\n",
      "Epoch 4: mean loss = 0.419, accuracy = 0.859\n",
      "validation\n",
      "Epoch 0: mean loss = 0.811, accuracy = 0.726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.81093341, 0.72619999999999996)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=100, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 11:45:56 Iter 0: batch trn loss = 0.269, accuracy = 0.930\n",
      "2017-10-29 11:47:04 Iter 100: batch trn loss = 0.330, accuracy = 0.920\n",
      "2017-10-29 11:48:12 Iter 200: batch trn loss = 0.439, accuracy = 0.850\n",
      "2017-10-29 11:49:19 Iter 300: batch trn loss = 0.350, accuracy = 0.880\n",
      "2017-10-29 11:50:24 Iter 400: batch trn loss = 0.419, accuracy = 0.880\n",
      "Epoch 0: mean loss = 0.317, accuracy = 0.897\n",
      "2017-10-29 11:51:29 Iter 500: batch trn loss = 0.212, accuracy = 0.960\n",
      "2017-10-29 11:52:35 Iter 600: batch trn loss = 0.160, accuracy = 0.970\n",
      "2017-10-29 11:53:43 Iter 700: batch trn loss = 0.156, accuracy = 0.980\n",
      "2017-10-29 11:54:50 Iter 800: batch trn loss = 0.225, accuracy = 0.920\n",
      "Epoch 1: mean loss = 0.234, accuracy = 0.927\n",
      "2017-10-29 11:55:56 Iter 900: batch trn loss = 0.127, accuracy = 0.980\n",
      "2017-10-29 11:57:02 Iter 1000: batch trn loss = 0.171, accuracy = 0.940\n",
      "2017-10-29 11:58:09 Iter 1100: batch trn loss = 0.124, accuracy = 0.980\n",
      "2017-10-29 11:59:16 Iter 1200: batch trn loss = 0.311, accuracy = 0.920\n",
      "2017-10-29 12:00:22 Iter 1300: batch trn loss = 0.221, accuracy = 0.950\n",
      "Epoch 2: mean loss = 0.161, accuracy = 0.956\n",
      "2017-10-29 12:01:30 Iter 1400: batch trn loss = 0.087, accuracy = 0.990\n",
      "2017-10-29 12:02:40 Iter 1500: batch trn loss = 0.102, accuracy = 0.970\n",
      "2017-10-29 12:03:54 Iter 1600: batch trn loss = 0.088, accuracy = 0.990\n",
      "2017-10-29 12:05:07 Iter 1700: batch trn loss = 0.068, accuracy = 0.980\n",
      "Epoch 3: mean loss = 0.101, accuracy = 0.979\n",
      "2017-10-29 12:06:15 Iter 1800: batch trn loss = 0.063, accuracy = 0.990\n",
      "2017-10-29 12:07:21 Iter 1900: batch trn loss = 0.051, accuracy = 0.990\n",
      "2017-10-29 12:08:25 Iter 2000: batch trn loss = 0.053, accuracy = 0.990\n",
      "2017-10-29 12:09:30 Iter 2100: batch trn loss = 0.069, accuracy = 1.000\n",
      "2017-10-29 12:10:35 Iter 2200: batch trn loss = 0.084, accuracy = 0.980\n",
      "Epoch 4: mean loss = 0.064, accuracy = 0.990\n",
      "validation\n",
      "Epoch 0: mean loss = 0.829, accuracy = 0.764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.82861483, 0.76400000000000001)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=100, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 12:11:20 Iter 0: batch trn loss = 0.027, accuracy = 1.000\n",
      "2017-10-29 12:12:26 Iter 100: batch trn loss = 0.040, accuracy = 1.000\n",
      "2017-10-29 12:13:30 Iter 200: batch trn loss = 0.061, accuracy = 0.990\n",
      "2017-10-29 12:14:34 Iter 300: batch trn loss = 0.063, accuracy = 1.000\n",
      "2017-10-29 12:15:37 Iter 400: batch trn loss = 0.023, accuracy = 1.000\n",
      "Epoch 0: mean loss = 0.041, accuracy = 0.996\n",
      "2017-10-29 12:16:41 Iter 500: batch trn loss = 0.040, accuracy = 0.990\n",
      "2017-10-29 12:17:45 Iter 600: batch trn loss = 0.027, accuracy = 1.000\n",
      "2017-10-29 12:18:51 Iter 700: batch trn loss = 0.025, accuracy = 1.000\n",
      "2017-10-29 12:19:58 Iter 800: batch trn loss = 0.023, accuracy = 1.000\n",
      "Epoch 1: mean loss = 0.028, accuracy = 0.998\n",
      "2017-10-29 12:21:04 Iter 900: batch trn loss = 0.024, accuracy = 1.000\n",
      "2017-10-29 12:22:11 Iter 1000: batch trn loss = 0.033, accuracy = 1.000\n",
      "2017-10-29 12:23:18 Iter 1100: batch trn loss = 0.025, accuracy = 1.000\n",
      "2017-10-29 12:24:25 Iter 1200: batch trn loss = 0.014, accuracy = 1.000\n",
      "2017-10-29 12:25:32 Iter 1300: batch trn loss = 0.024, accuracy = 1.000\n",
      "Epoch 2: mean loss = 0.019, accuracy = 1.000\n",
      "2017-10-29 12:26:41 Iter 1400: batch trn loss = 0.011, accuracy = 1.000\n",
      "2017-10-29 12:27:48 Iter 1500: batch trn loss = 0.017, accuracy = 1.000\n",
      "2017-10-29 12:28:56 Iter 1600: batch trn loss = 0.012, accuracy = 1.000\n",
      "2017-10-29 12:30:03 Iter 1700: batch trn loss = 0.011, accuracy = 1.000\n",
      "Epoch 3: mean loss = 0.016, accuracy = 1.000\n",
      "2017-10-29 12:31:07 Iter 1800: batch trn loss = 0.014, accuracy = 1.000\n",
      "2017-10-29 12:32:12 Iter 1900: batch trn loss = 0.011, accuracy = 1.000\n",
      "2017-10-29 12:33:17 Iter 2000: batch trn loss = 0.010, accuracy = 1.000\n",
      "2017-10-29 12:34:22 Iter 2100: batch trn loss = 0.012, accuracy = 1.000\n",
      "2017-10-29 12:35:26 Iter 2200: batch trn loss = 0.016, accuracy = 1.000\n",
      "Epoch 4: mean loss = 0.012, accuracy = 1.000\n",
      "validation\n",
      "Epoch 0: mean loss = 0.857, accuracy = 0.777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85706973, 0.77700000000000002)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=100, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0103] witness + dropout\n",
    "- base (0101): add witness and dropout = 0.5\n",
    "- batch size still 50\n",
    "- trn: , val: (05 epochs)\n",
    "- trn: , val: (10 epochs)\n",
    "- trn: , val: (15 epochs)\n",
    "- trn: , val: (20 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3136\n"
     ]
    }
   ],
   "source": [
    "def model_fn(layer_input, labels, is_training):\n",
    "    reg_scale= 0.1\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=reg_scale)\n",
    "    # initializer = tf.contrib.layers.xavier_initializer()\n",
    "    initializer = None\n",
    "    h, w = H, W\n",
    "    # conv - bn - max_pool\n",
    "    F1 = 64\n",
    "    P1, S1 = 3, 2 # pool_size, strides\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=layer_input, filters=F1, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, training=is_training,\n",
    "        beta_regularizer=regularizer, gamma_regularizer=regularizer)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=P1, strides=S1)\n",
    "    h = math.floor((h - P1 + S1) / S1)\n",
    "    w = math.floor((w - P1 + S1) / S1)\n",
    "    # conv - bn - max_pool\n",
    "    F2 = 64\n",
    "    P2, S2 = 3, 2 # pool_size, strides\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=layer, filters=F2, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, training=is_training,\n",
    "        beta_regularizer=regularizer, gamma_regularizer=regularizer)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=P2, strides=S2)\n",
    "    h = math.floor((h - P2 + S2) / S2)\n",
    "    w = math.floor((w - P2 + S2) / S2)\n",
    "    # dense1 - bn - dropout - fc - softmax\n",
    "    flat_size = F2 * h * w\n",
    "    print(flat_size)\n",
    "    layer = tf.reshape(layer, [-1, flat_size])\n",
    "    layer = tf.layers.dense(\n",
    "        inputs=layer, units=1024, activation=tf.nn.relu,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, training=is_training,\n",
    "        beta_regularizer=regularizer, gamma_regularizer=regularizer)\n",
    "    layer = tf.layers.dropout(inputs=layer, rate=0.5, training=is_training)\n",
    "    # no activation here for logit, as it will be calculated in loss\n",
    "    logit = tf.layers.dense(\n",
    "        inputs=layer, units=T, activation=None,\n",
    "        kernel_regularizer=regularizer, kernel_initializer=initializer)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int64), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logit)\n",
    "    return logit, loss\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "cnn = CNN(model_fn, trainer)\n",
    "cnns['0103'] = cnn\n",
    "\n",
    "m_X_trn = witness(X_trn)\n",
    "m_X_val = witness(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 12:55:58 Iter 0: batch trn loss = 3.171, accuracy = 0.120\n",
      "2017-10-29 12:56:31 Iter 100: batch trn loss = 1.984, accuracy = 0.360\n",
      "2017-10-29 12:57:05 Iter 200: batch trn loss = 1.572, accuracy = 0.360\n",
      "2017-10-29 12:57:40 Iter 300: batch trn loss = 1.628, accuracy = 0.520\n",
      "2017-10-29 12:58:12 Iter 400: batch trn loss = 1.474, accuracy = 0.480\n",
      "2017-10-29 12:58:44 Iter 500: batch trn loss = 1.485, accuracy = 0.480\n",
      "2017-10-29 12:59:17 Iter 600: batch trn loss = 1.381, accuracy = 0.580\n",
      "2017-10-29 12:59:49 Iter 700: batch trn loss = 1.681, accuracy = 0.440\n",
      "2017-10-29 13:00:21 Iter 800: batch trn loss = 0.820, accuracy = 0.700\n",
      "Epoch 0: mean loss = 1.607, accuracy = 0.486\n",
      "2017-10-29 13:00:53 Iter 900: batch trn loss = 1.120, accuracy = 0.600\n",
      "2017-10-29 13:01:26 Iter 1000: batch trn loss = 1.241, accuracy = 0.640\n",
      "2017-10-29 13:01:58 Iter 1100: batch trn loss = 1.265, accuracy = 0.520\n",
      "2017-10-29 13:02:31 Iter 1200: batch trn loss = 0.929, accuracy = 0.700\n",
      "2017-10-29 13:03:03 Iter 1300: batch trn loss = 1.136, accuracy = 0.680\n",
      "2017-10-29 13:03:35 Iter 1400: batch trn loss = 1.025, accuracy = 0.680\n",
      "2017-10-29 13:04:07 Iter 1500: batch trn loss = 0.905, accuracy = 0.620\n",
      "2017-10-29 13:04:39 Iter 1600: batch trn loss = 0.780, accuracy = 0.720\n",
      "2017-10-29 13:05:11 Iter 1700: batch trn loss = 1.112, accuracy = 0.640\n",
      "Epoch 1: mean loss = 1.101, accuracy = 0.626\n",
      "2017-10-29 13:05:43 Iter 1800: batch trn loss = 1.148, accuracy = 0.600\n",
      "2017-10-29 13:06:15 Iter 1900: batch trn loss = 0.821, accuracy = 0.740\n",
      "2017-10-29 13:06:47 Iter 2000: batch trn loss = 0.893, accuracy = 0.720\n",
      "2017-10-29 13:07:19 Iter 2100: batch trn loss = 0.960, accuracy = 0.740\n",
      "2017-10-29 13:07:51 Iter 2200: batch trn loss = 0.924, accuracy = 0.680\n",
      "2017-10-29 13:08:25 Iter 2300: batch trn loss = 0.814, accuracy = 0.740\n",
      "2017-10-29 13:09:03 Iter 2400: batch trn loss = 1.227, accuracy = 0.560\n",
      "2017-10-29 13:09:40 Iter 2500: batch trn loss = 0.693, accuracy = 0.780\n",
      "2017-10-29 13:10:29 Iter 2600: batch trn loss = 0.857, accuracy = 0.660\n",
      "Epoch 2: mean loss = 0.939, accuracy = 0.681\n",
      "2017-10-29 13:11:17 Iter 2700: batch trn loss = 0.619, accuracy = 0.800\n",
      "2017-10-29 13:12:05 Iter 2800: batch trn loss = 0.767, accuracy = 0.800\n",
      "2017-10-29 13:12:54 Iter 2900: batch trn loss = 0.646, accuracy = 0.800\n",
      "2017-10-29 13:13:44 Iter 3000: batch trn loss = 0.709, accuracy = 0.760\n",
      "2017-10-29 13:14:31 Iter 3100: batch trn loss = 0.939, accuracy = 0.720\n",
      "2017-10-29 13:15:20 Iter 3200: batch trn loss = 0.743, accuracy = 0.680\n",
      "2017-10-29 13:16:09 Iter 3300: batch trn loss = 0.939, accuracy = 0.720\n",
      "2017-10-29 13:16:59 Iter 3400: batch trn loss = 0.552, accuracy = 0.820\n",
      "2017-10-29 13:17:49 Iter 3500: batch trn loss = 1.058, accuracy = 0.700\n",
      "Epoch 3: mean loss = 0.834, accuracy = 0.718\n",
      "2017-10-29 13:18:39 Iter 3600: batch trn loss = 0.905, accuracy = 0.740\n",
      "2017-10-29 13:19:29 Iter 3700: batch trn loss = 0.455, accuracy = 0.760\n",
      "2017-10-29 13:20:20 Iter 3800: batch trn loss = 0.837, accuracy = 0.660\n",
      "2017-10-29 13:21:11 Iter 3900: batch trn loss = 1.232, accuracy = 0.620\n",
      "2017-10-29 13:22:00 Iter 4000: batch trn loss = 1.065, accuracy = 0.720\n",
      "2017-10-29 13:22:50 Iter 4100: batch trn loss = 0.595, accuracy = 0.820\n",
      "2017-10-29 13:23:39 Iter 4200: batch trn loss = 0.564, accuracy = 0.780\n",
      "2017-10-29 13:24:29 Iter 4300: batch trn loss = 0.691, accuracy = 0.780\n",
      "2017-10-29 13:25:33 Iter 4400: batch trn loss = 0.487, accuracy = 0.800\n",
      "Epoch 4: mean loss = 0.747, accuracy = 0.743\n",
      "validation\n",
      "Epoch 0: mean loss = 0.773, accuracy = 0.740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.77256513, 0.73980000000000001)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=50, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 14:29:36 Iter 0: batch trn loss = 0.789, accuracy = 0.760\n",
      "2017-10-29 14:30:11 Iter 100: batch trn loss = 0.295, accuracy = 0.900\n",
      "2017-10-29 14:30:45 Iter 200: batch trn loss = 0.714, accuracy = 0.800\n",
      "2017-10-29 14:31:18 Iter 300: batch trn loss = 0.900, accuracy = 0.680\n",
      "2017-10-29 14:31:51 Iter 400: batch trn loss = 0.469, accuracy = 0.860\n",
      "2017-10-29 14:32:26 Iter 500: batch trn loss = 0.980, accuracy = 0.720\n",
      "2017-10-29 14:32:58 Iter 600: batch trn loss = 1.012, accuracy = 0.740\n",
      "2017-10-29 14:33:31 Iter 700: batch trn loss = 0.525, accuracy = 0.820\n",
      "2017-10-29 14:34:03 Iter 800: batch trn loss = 0.737, accuracy = 0.740\n",
      "Epoch 0: mean loss = 0.683, accuracy = 0.768\n",
      "2017-10-29 14:34:35 Iter 900: batch trn loss = 0.579, accuracy = 0.820\n",
      "2017-10-29 14:35:08 Iter 1000: batch trn loss = 0.526, accuracy = 0.740\n",
      "2017-10-29 14:35:40 Iter 1100: batch trn loss = 0.613, accuracy = 0.820\n",
      "2017-10-29 14:36:12 Iter 1200: batch trn loss = 0.534, accuracy = 0.760\n",
      "2017-10-29 14:36:44 Iter 1300: batch trn loss = 0.537, accuracy = 0.800\n",
      "2017-10-29 14:37:17 Iter 1400: batch trn loss = 0.630, accuracy = 0.820\n",
      "2017-10-29 14:37:49 Iter 1500: batch trn loss = 0.486, accuracy = 0.820\n",
      "2017-10-29 14:38:21 Iter 1600: batch trn loss = 0.735, accuracy = 0.740\n",
      "2017-10-29 14:38:53 Iter 1700: batch trn loss = 0.862, accuracy = 0.660\n",
      "Epoch 1: mean loss = 0.627, accuracy = 0.782\n",
      "2017-10-29 14:39:26 Iter 1800: batch trn loss = 0.766, accuracy = 0.760\n",
      "2017-10-29 14:39:58 Iter 1900: batch trn loss = 0.464, accuracy = 0.820\n",
      "2017-10-29 14:40:30 Iter 2000: batch trn loss = 0.671, accuracy = 0.780\n",
      "2017-10-29 14:41:03 Iter 2100: batch trn loss = 0.487, accuracy = 0.800\n",
      "2017-10-29 14:41:35 Iter 2200: batch trn loss = 0.505, accuracy = 0.820\n",
      "2017-10-29 14:42:08 Iter 2300: batch trn loss = 0.281, accuracy = 0.940\n",
      "2017-10-29 14:42:41 Iter 2400: batch trn loss = 0.542, accuracy = 0.840\n",
      "2017-10-29 14:43:13 Iter 2500: batch trn loss = 0.531, accuracy = 0.820\n",
      "2017-10-29 14:43:45 Iter 2600: batch trn loss = 0.732, accuracy = 0.700\n",
      "Epoch 2: mean loss = 0.566, accuracy = 0.803\n",
      "2017-10-29 14:44:17 Iter 2700: batch trn loss = 0.552, accuracy = 0.800\n",
      "2017-10-29 14:44:49 Iter 2800: batch trn loss = 0.589, accuracy = 0.820\n",
      "2017-10-29 14:45:20 Iter 2900: batch trn loss = 0.788, accuracy = 0.780\n",
      "2017-10-29 14:45:52 Iter 3000: batch trn loss = 0.477, accuracy = 0.740\n",
      "2017-10-29 14:46:24 Iter 3100: batch trn loss = 0.438, accuracy = 0.860\n",
      "2017-10-29 14:46:56 Iter 3200: batch trn loss = 0.456, accuracy = 0.840\n",
      "2017-10-29 14:47:28 Iter 3300: batch trn loss = 0.791, accuracy = 0.780\n",
      "2017-10-29 14:48:00 Iter 3400: batch trn loss = 0.687, accuracy = 0.820\n",
      "2017-10-29 14:48:32 Iter 3500: batch trn loss = 0.512, accuracy = 0.780\n",
      "Epoch 3: mean loss = 0.523, accuracy = 0.818\n",
      "2017-10-29 14:49:04 Iter 3600: batch trn loss = 0.430, accuracy = 0.880\n",
      "2017-10-29 14:49:36 Iter 3700: batch trn loss = 0.736, accuracy = 0.780\n",
      "2017-10-29 14:50:08 Iter 3800: batch trn loss = 0.442, accuracy = 0.840\n",
      "2017-10-29 14:50:40 Iter 3900: batch trn loss = 0.485, accuracy = 0.840\n",
      "2017-10-29 14:51:12 Iter 4000: batch trn loss = 0.614, accuracy = 0.780\n",
      "2017-10-29 14:51:44 Iter 4100: batch trn loss = 0.406, accuracy = 0.900\n",
      "2017-10-29 14:52:16 Iter 4200: batch trn loss = 0.443, accuracy = 0.840\n",
      "2017-10-29 14:52:48 Iter 4300: batch trn loss = 0.556, accuracy = 0.800\n",
      "2017-10-29 14:53:20 Iter 4400: batch trn loss = 0.636, accuracy = 0.740\n",
      "Epoch 4: mean loss = 0.483, accuracy = 0.831\n",
      "validation\n",
      "Epoch 0: mean loss = 0.700, accuracy = 0.774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.69985479, 0.77359999999999995)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=50, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 14:54:04 Iter 0: batch trn loss = 0.442, accuracy = 0.840\n",
      "2017-10-29 14:54:36 Iter 100: batch trn loss = 0.553, accuracy = 0.860\n",
      "2017-10-29 14:55:08 Iter 200: batch trn loss = 0.305, accuracy = 0.920\n",
      "2017-10-29 14:55:40 Iter 300: batch trn loss = 0.427, accuracy = 0.880\n",
      "2017-10-29 14:56:12 Iter 400: batch trn loss = 0.415, accuracy = 0.880\n",
      "2017-10-29 14:56:44 Iter 500: batch trn loss = 0.399, accuracy = 0.820\n",
      "2017-10-29 14:57:16 Iter 600: batch trn loss = 0.434, accuracy = 0.880\n",
      "2017-10-29 14:57:48 Iter 700: batch trn loss = 0.358, accuracy = 0.860\n",
      "2017-10-29 14:58:20 Iter 800: batch trn loss = 0.412, accuracy = 0.860\n",
      "Epoch 0: mean loss = 0.441, accuracy = 0.845\n",
      "2017-10-29 14:58:52 Iter 900: batch trn loss = 0.365, accuracy = 0.880\n",
      "2017-10-29 14:59:24 Iter 1000: batch trn loss = 0.640, accuracy = 0.800\n",
      "2017-10-29 14:59:56 Iter 1100: batch trn loss = 0.383, accuracy = 0.900\n",
      "2017-10-29 15:00:28 Iter 1200: batch trn loss = 0.453, accuracy = 0.840\n",
      "2017-10-29 15:01:00 Iter 1300: batch trn loss = 0.578, accuracy = 0.820\n",
      "2017-10-29 15:01:32 Iter 1400: batch trn loss = 0.417, accuracy = 0.860\n",
      "2017-10-29 15:02:04 Iter 1500: batch trn loss = 0.381, accuracy = 0.880\n",
      "2017-10-29 15:02:36 Iter 1600: batch trn loss = 0.271, accuracy = 0.900\n",
      "2017-10-29 15:03:08 Iter 1700: batch trn loss = 0.327, accuracy = 0.880\n",
      "Epoch 1: mean loss = 0.410, accuracy = 0.856\n",
      "2017-10-29 15:03:39 Iter 1800: batch trn loss = 0.351, accuracy = 0.880\n",
      "2017-10-29 15:04:11 Iter 1900: batch trn loss = 0.176, accuracy = 0.920\n",
      "2017-10-29 15:04:43 Iter 2000: batch trn loss = 0.207, accuracy = 0.940\n",
      "2017-10-29 15:05:15 Iter 2100: batch trn loss = 0.158, accuracy = 0.940\n",
      "2017-10-29 15:05:47 Iter 2200: batch trn loss = 0.409, accuracy = 0.800\n",
      "2017-10-29 15:06:19 Iter 2300: batch trn loss = 0.423, accuracy = 0.860\n",
      "2017-10-29 15:06:51 Iter 2400: batch trn loss = 0.727, accuracy = 0.760\n",
      "2017-10-29 15:07:23 Iter 2500: batch trn loss = 0.308, accuracy = 0.920\n",
      "2017-10-29 15:07:55 Iter 2600: batch trn loss = 0.263, accuracy = 0.920\n",
      "Epoch 2: mean loss = 0.373, accuracy = 0.868\n",
      "2017-10-29 15:08:27 Iter 2700: batch trn loss = 0.286, accuracy = 0.880\n",
      "2017-10-29 15:08:59 Iter 2800: batch trn loss = 0.620, accuracy = 0.840\n",
      "2017-10-29 15:09:31 Iter 2900: batch trn loss = 0.270, accuracy = 0.920\n",
      "2017-10-29 15:10:03 Iter 3000: batch trn loss = 0.331, accuracy = 0.900\n",
      "2017-10-29 15:10:35 Iter 3100: batch trn loss = 0.519, accuracy = 0.840\n",
      "2017-10-29 15:11:07 Iter 3200: batch trn loss = 0.365, accuracy = 0.900\n",
      "2017-10-29 15:11:39 Iter 3300: batch trn loss = 0.264, accuracy = 0.880\n",
      "2017-10-29 15:12:11 Iter 3400: batch trn loss = 0.233, accuracy = 0.940\n",
      "2017-10-29 15:12:47 Iter 3500: batch trn loss = 0.385, accuracy = 0.860\n",
      "Epoch 3: mean loss = 0.347, accuracy = 0.877\n",
      "2017-10-29 15:13:19 Iter 3600: batch trn loss = 0.321, accuracy = 0.860\n",
      "2017-10-29 15:13:51 Iter 3700: batch trn loss = 0.235, accuracy = 0.920\n",
      "2017-10-29 15:14:22 Iter 3800: batch trn loss = 0.418, accuracy = 0.860\n",
      "2017-10-29 15:14:54 Iter 3900: batch trn loss = 0.267, accuracy = 0.900\n",
      "2017-10-29 15:15:26 Iter 4000: batch trn loss = 0.276, accuracy = 0.940\n",
      "2017-10-29 15:15:58 Iter 4100: batch trn loss = 0.321, accuracy = 0.920\n",
      "2017-10-29 15:16:30 Iter 4200: batch trn loss = 0.156, accuracy = 0.960\n",
      "2017-10-29 15:17:02 Iter 4300: batch trn loss = 0.345, accuracy = 0.880\n",
      "2017-10-29 15:17:34 Iter 4400: batch trn loss = 0.236, accuracy = 0.880\n",
      "Epoch 4: mean loss = 0.315, accuracy = 0.889\n",
      "validation\n",
      "Epoch 0: mean loss = 0.706, accuracy = 0.794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.70572072, 0.79359999999999997)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=50, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 15:53:00 Iter 0: batch trn loss = 0.115, accuracy = 0.980\n",
      "2017-10-29 15:53:34 Iter 100: batch trn loss = 0.162, accuracy = 0.980\n",
      "2017-10-29 15:54:08 Iter 200: batch trn loss = 0.306, accuracy = 0.880\n",
      "2017-10-29 15:54:41 Iter 300: batch trn loss = 0.385, accuracy = 0.840\n",
      "2017-10-29 15:55:15 Iter 400: batch trn loss = 0.320, accuracy = 0.860\n",
      "2017-10-29 15:55:52 Iter 500: batch trn loss = 0.191, accuracy = 0.940\n",
      "2017-10-29 15:56:27 Iter 600: batch trn loss = 0.373, accuracy = 0.920\n",
      "2017-10-29 15:57:00 Iter 700: batch trn loss = 0.351, accuracy = 0.880\n",
      "2017-10-29 15:57:33 Iter 800: batch trn loss = 0.512, accuracy = 0.860\n",
      "Epoch 0: mean loss = 0.290, accuracy = 0.896\n",
      "2017-10-29 15:58:06 Iter 900: batch trn loss = 0.363, accuracy = 0.820\n",
      "2017-10-29 15:58:40 Iter 1000: batch trn loss = 0.248, accuracy = 0.840\n",
      "2017-10-29 15:59:13 Iter 1100: batch trn loss = 0.346, accuracy = 0.860\n",
      "2017-10-29 15:59:47 Iter 1200: batch trn loss = 0.129, accuracy = 0.940\n",
      "2017-10-29 16:00:21 Iter 1300: batch trn loss = 0.277, accuracy = 0.900\n",
      "2017-10-29 16:00:54 Iter 1400: batch trn loss = 0.193, accuracy = 0.960\n",
      "2017-10-29 16:01:29 Iter 1500: batch trn loss = 0.228, accuracy = 0.880\n",
      "2017-10-29 16:02:03 Iter 1600: batch trn loss = 0.327, accuracy = 0.860\n",
      "2017-10-29 16:02:38 Iter 1700: batch trn loss = 0.397, accuracy = 0.920\n",
      "Epoch 1: mean loss = 0.269, accuracy = 0.904\n",
      "2017-10-29 16:03:11 Iter 1800: batch trn loss = 0.218, accuracy = 0.920\n",
      "2017-10-29 16:03:45 Iter 1900: batch trn loss = 0.266, accuracy = 0.900\n",
      "2017-10-29 16:04:20 Iter 2000: batch trn loss = 0.149, accuracy = 0.980\n",
      "2017-10-29 16:04:54 Iter 2100: batch trn loss = 0.098, accuracy = 0.980\n",
      "2017-10-29 16:05:28 Iter 2200: batch trn loss = 0.083, accuracy = 0.980\n",
      "2017-10-29 16:06:01 Iter 2300: batch trn loss = 0.331, accuracy = 0.900\n",
      "2017-10-29 16:06:36 Iter 2400: batch trn loss = 0.197, accuracy = 0.940\n",
      "2017-10-29 16:07:12 Iter 2500: batch trn loss = 0.233, accuracy = 0.860\n",
      "2017-10-29 16:07:45 Iter 2600: batch trn loss = 0.373, accuracy = 0.840\n",
      "Epoch 2: mean loss = 0.249, accuracy = 0.910\n",
      "2017-10-29 16:08:18 Iter 2700: batch trn loss = 0.108, accuracy = 0.960\n",
      "2017-10-29 16:08:51 Iter 2800: batch trn loss = 0.136, accuracy = 0.940\n",
      "2017-10-29 16:09:25 Iter 2900: batch trn loss = 0.278, accuracy = 0.920\n",
      "2017-10-29 16:09:59 Iter 3000: batch trn loss = 0.171, accuracy = 0.940\n",
      "2017-10-29 16:10:31 Iter 3100: batch trn loss = 0.142, accuracy = 0.940\n",
      "2017-10-29 16:11:06 Iter 3200: batch trn loss = 0.203, accuracy = 0.920\n",
      "2017-10-29 16:11:39 Iter 3300: batch trn loss = 0.229, accuracy = 0.920\n",
      "2017-10-29 16:12:13 Iter 3400: batch trn loss = 0.291, accuracy = 0.900\n",
      "2017-10-29 16:12:49 Iter 3500: batch trn loss = 0.492, accuracy = 0.880\n",
      "Epoch 3: mean loss = 0.225, accuracy = 0.919\n",
      "2017-10-29 16:13:24 Iter 3600: batch trn loss = 0.078, accuracy = 0.980\n",
      "2017-10-29 16:13:58 Iter 3700: batch trn loss = 0.162, accuracy = 0.940\n",
      "2017-10-29 16:14:31 Iter 3800: batch trn loss = 0.182, accuracy = 0.940\n",
      "2017-10-29 16:15:04 Iter 3900: batch trn loss = 0.540, accuracy = 0.780\n",
      "2017-10-29 16:15:45 Iter 4000: batch trn loss = 0.273, accuracy = 0.880\n",
      "2017-10-29 16:16:19 Iter 4100: batch trn loss = 0.240, accuracy = 0.920\n",
      "2017-10-29 16:16:55 Iter 4200: batch trn loss = 0.308, accuracy = 0.900\n",
      "2017-10-29 16:17:28 Iter 4300: batch trn loss = 0.147, accuracy = 0.940\n",
      "2017-10-29 16:18:01 Iter 4400: batch trn loss = 0.232, accuracy = 0.900\n",
      "Epoch 4: mean loss = 0.213, accuracy = 0.924\n",
      "validation\n",
      "Epoch 0: mean loss = 0.755, accuracy = 0.802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7545625, 0.80220000000000002)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=50, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 16:18:47 Iter 0: batch trn loss = 0.268, accuracy = 0.920\n",
      "2017-10-29 16:19:21 Iter 100: batch trn loss = 0.071, accuracy = 0.960\n",
      "2017-10-29 16:19:54 Iter 200: batch trn loss = 0.121, accuracy = 0.940\n",
      "2017-10-29 16:20:27 Iter 300: batch trn loss = 0.147, accuracy = 0.960\n",
      "2017-10-29 16:21:00 Iter 400: batch trn loss = 0.162, accuracy = 0.940\n",
      "2017-10-29 16:21:34 Iter 500: batch trn loss = 0.143, accuracy = 0.960\n",
      "2017-10-29 16:22:08 Iter 600: batch trn loss = 0.077, accuracy = 0.980\n",
      "2017-10-29 16:22:44 Iter 700: batch trn loss = 0.201, accuracy = 0.960\n",
      "2017-10-29 16:23:19 Iter 800: batch trn loss = 0.207, accuracy = 0.900\n",
      "Epoch 0: mean loss = 0.203, accuracy = 0.927\n",
      "2017-10-29 16:23:52 Iter 900: batch trn loss = 0.252, accuracy = 0.940\n",
      "2017-10-29 16:24:26 Iter 1000: batch trn loss = 0.190, accuracy = 0.940\n",
      "2017-10-29 16:24:59 Iter 1100: batch trn loss = 0.207, accuracy = 0.940\n",
      "2017-10-29 16:25:33 Iter 1200: batch trn loss = 0.176, accuracy = 0.900\n",
      "2017-10-29 16:26:06 Iter 1300: batch trn loss = 0.109, accuracy = 0.960\n",
      "2017-10-29 16:26:40 Iter 1400: batch trn loss = 0.208, accuracy = 0.940\n",
      "2017-10-29 16:27:13 Iter 1500: batch trn loss = 0.095, accuracy = 1.000\n",
      "2017-10-29 16:27:47 Iter 1600: batch trn loss = 0.282, accuracy = 0.900\n",
      "2017-10-29 16:28:20 Iter 1700: batch trn loss = 0.217, accuracy = 0.940\n",
      "Epoch 1: mean loss = 0.186, accuracy = 0.933\n",
      "2017-10-29 16:28:55 Iter 1800: batch trn loss = 0.186, accuracy = 0.920\n",
      "2017-10-29 16:29:30 Iter 1900: batch trn loss = 0.119, accuracy = 0.960\n",
      "2017-10-29 16:30:05 Iter 2000: batch trn loss = 0.075, accuracy = 1.000\n",
      "2017-10-29 16:30:39 Iter 2100: batch trn loss = 0.141, accuracy = 0.940\n",
      "2017-10-29 16:31:12 Iter 2200: batch trn loss = 0.069, accuracy = 0.960\n",
      "2017-10-29 16:31:46 Iter 2300: batch trn loss = 0.225, accuracy = 0.920\n",
      "2017-10-29 16:32:19 Iter 2400: batch trn loss = 0.187, accuracy = 0.940\n",
      "2017-10-29 16:32:53 Iter 2500: batch trn loss = 0.125, accuracy = 0.960\n",
      "2017-10-29 16:33:26 Iter 2600: batch trn loss = 0.143, accuracy = 0.960\n",
      "Epoch 2: mean loss = 0.174, accuracy = 0.939\n",
      "2017-10-29 16:33:59 Iter 2700: batch trn loss = 0.086, accuracy = 0.980\n",
      "2017-10-29 16:34:35 Iter 2800: batch trn loss = 0.200, accuracy = 0.960\n",
      "2017-10-29 16:35:08 Iter 2900: batch trn loss = 0.304, accuracy = 0.920\n",
      "2017-10-29 16:35:40 Iter 3000: batch trn loss = 0.074, accuracy = 0.960\n",
      "2017-10-29 16:36:13 Iter 3100: batch trn loss = 0.083, accuracy = 0.980\n",
      "2017-10-29 16:36:46 Iter 3200: batch trn loss = 0.296, accuracy = 0.920\n",
      "2017-10-29 16:37:20 Iter 3300: batch trn loss = 0.300, accuracy = 0.900\n",
      "2017-10-29 16:37:54 Iter 3400: batch trn loss = 0.180, accuracy = 0.920\n",
      "2017-10-29 16:38:28 Iter 3500: batch trn loss = 0.168, accuracy = 0.920\n",
      "Epoch 3: mean loss = 0.171, accuracy = 0.939\n",
      "2017-10-29 16:39:02 Iter 3600: batch trn loss = 0.128, accuracy = 0.940\n",
      "2017-10-29 16:39:36 Iter 3700: batch trn loss = 0.217, accuracy = 0.940\n",
      "2017-10-29 16:40:09 Iter 3800: batch trn loss = 0.250, accuracy = 0.900\n",
      "2017-10-29 16:40:44 Iter 3900: batch trn loss = 0.143, accuracy = 0.920\n",
      "2017-10-29 16:41:17 Iter 4000: batch trn loss = 0.202, accuracy = 0.920\n",
      "2017-10-29 16:41:50 Iter 4100: batch trn loss = 0.286, accuracy = 0.860\n",
      "2017-10-29 16:42:23 Iter 4200: batch trn loss = 0.240, accuracy = 0.920\n",
      "2017-10-29 16:42:57 Iter 4300: batch trn loss = 0.246, accuracy = 0.900\n",
      "2017-10-29 16:43:29 Iter 4400: batch trn loss = 0.080, accuracy = 1.000\n",
      "Epoch 4: mean loss = 0.162, accuracy = 0.942\n",
      "validation\n",
      "Epoch 0: mean loss = 0.793, accuracy = 0.797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.79273933, 0.79679999999999995)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=50, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 17:17:07 Iter 0: batch trn loss = 0.086, accuracy = 0.980\n",
      "2017-10-29 17:17:40 Iter 100: batch trn loss = 0.197, accuracy = 0.940\n",
      "2017-10-29 17:18:13 Iter 200: batch trn loss = 0.107, accuracy = 0.980\n",
      "2017-10-29 17:18:45 Iter 300: batch trn loss = 0.257, accuracy = 0.860\n",
      "2017-10-29 17:19:18 Iter 400: batch trn loss = 0.142, accuracy = 0.960\n",
      "2017-10-29 17:19:50 Iter 500: batch trn loss = 0.284, accuracy = 0.900\n",
      "2017-10-29 17:20:24 Iter 600: batch trn loss = 0.243, accuracy = 0.920\n",
      "2017-10-29 17:20:57 Iter 700: batch trn loss = 0.089, accuracy = 0.980\n",
      "2017-10-29 17:21:31 Iter 800: batch trn loss = 0.206, accuracy = 0.920\n",
      "Epoch 0: mean loss = 0.147, accuracy = 0.947\n",
      "2017-10-29 17:22:04 Iter 900: batch trn loss = 0.014, accuracy = 1.000\n",
      "2017-10-29 17:22:37 Iter 1000: batch trn loss = 0.042, accuracy = 1.000\n",
      "2017-10-29 17:23:10 Iter 1100: batch trn loss = 0.062, accuracy = 0.980\n",
      "2017-10-29 17:23:43 Iter 1200: batch trn loss = 0.112, accuracy = 0.960\n",
      "2017-10-29 17:24:16 Iter 1300: batch trn loss = 0.042, accuracy = 1.000\n",
      "2017-10-29 17:24:49 Iter 1400: batch trn loss = 0.182, accuracy = 0.940\n",
      "2017-10-29 17:25:22 Iter 1500: batch trn loss = 0.165, accuracy = 0.920\n",
      "2017-10-29 17:25:56 Iter 1600: batch trn loss = 0.104, accuracy = 0.980\n",
      "2017-10-29 17:26:29 Iter 1700: batch trn loss = 0.125, accuracy = 0.960\n",
      "Epoch 1: mean loss = 0.137, accuracy = 0.950\n",
      "2017-10-29 17:27:02 Iter 1800: batch trn loss = 0.056, accuracy = 1.000\n",
      "2017-10-29 17:27:34 Iter 1900: batch trn loss = 0.079, accuracy = 0.940\n",
      "2017-10-29 17:28:07 Iter 2000: batch trn loss = 0.154, accuracy = 0.920\n",
      "2017-10-29 17:28:41 Iter 2100: batch trn loss = 0.048, accuracy = 0.980\n",
      "2017-10-29 17:29:14 Iter 2200: batch trn loss = 0.232, accuracy = 0.940\n",
      "2017-10-29 17:29:48 Iter 2300: batch trn loss = 0.036, accuracy = 1.000\n",
      "2017-10-29 17:30:22 Iter 2400: batch trn loss = 0.179, accuracy = 0.920\n",
      "2017-10-29 17:30:56 Iter 2500: batch trn loss = 0.199, accuracy = 0.920\n",
      "2017-10-29 17:31:30 Iter 2600: batch trn loss = 0.378, accuracy = 0.860\n",
      "Epoch 2: mean loss = 0.120, accuracy = 0.958\n",
      "2017-10-29 17:32:06 Iter 2700: batch trn loss = 0.099, accuracy = 0.980\n",
      "2017-10-29 17:32:40 Iter 2800: batch trn loss = 0.144, accuracy = 0.960\n",
      "2017-10-29 17:33:13 Iter 2900: batch trn loss = 0.380, accuracy = 0.900\n",
      "2017-10-29 17:33:46 Iter 3000: batch trn loss = 0.046, accuracy = 1.000\n",
      "2017-10-29 17:34:20 Iter 3100: batch trn loss = 0.103, accuracy = 0.960\n",
      "2017-10-29 17:34:54 Iter 3200: batch trn loss = 0.337, accuracy = 0.900\n",
      "2017-10-29 17:35:28 Iter 3300: batch trn loss = 0.079, accuracy = 0.960\n",
      "2017-10-29 17:36:02 Iter 3400: batch trn loss = 0.144, accuracy = 0.980\n",
      "2017-10-29 17:36:35 Iter 3500: batch trn loss = 0.028, accuracy = 1.000\n",
      "Epoch 3: mean loss = 0.113, accuracy = 0.960\n",
      "2017-10-29 17:37:10 Iter 3600: batch trn loss = 0.210, accuracy = 0.920\n",
      "2017-10-29 17:37:43 Iter 3700: batch trn loss = 0.081, accuracy = 0.960\n",
      "2017-10-29 17:38:16 Iter 3800: batch trn loss = 0.109, accuracy = 0.960\n",
      "2017-10-29 17:38:49 Iter 3900: batch trn loss = 0.033, accuracy = 1.000\n",
      "2017-10-29 17:39:21 Iter 4000: batch trn loss = 0.030, accuracy = 0.980\n",
      "2017-10-29 17:39:55 Iter 4100: batch trn loss = 0.320, accuracy = 0.900\n",
      "2017-10-29 17:40:29 Iter 4200: batch trn loss = 0.098, accuracy = 0.940\n",
      "2017-10-29 17:41:01 Iter 4300: batch trn loss = 0.211, accuracy = 0.940\n",
      "2017-10-29 17:41:34 Iter 4400: batch trn loss = 0.078, accuracy = 1.000\n",
      "Epoch 4: mean loss = 0.113, accuracy = 0.960\n",
      "validation\n",
      "Epoch 0: mean loss = 0.870, accuracy = 0.802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.86955673, 0.80159999999999998)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=50, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "2017-10-29 18:43:59 Iter 0: batch trn loss = 0.073, accuracy = 0.980\n",
      "2017-10-29 18:44:31 Iter 100: batch trn loss = 0.135, accuracy = 0.960\n",
      "2017-10-29 18:45:03 Iter 200: batch trn loss = 0.019, accuracy = 1.000\n",
      "2017-10-29 18:45:36 Iter 300: batch trn loss = 0.039, accuracy = 0.980\n",
      "2017-10-29 18:46:08 Iter 400: batch trn loss = 0.072, accuracy = 0.980\n",
      "2017-10-29 18:46:40 Iter 500: batch trn loss = 0.268, accuracy = 0.900\n",
      "2017-10-29 18:47:12 Iter 600: batch trn loss = 0.011, accuracy = 1.000\n",
      "2017-10-29 18:47:44 Iter 700: batch trn loss = 0.275, accuracy = 0.820\n",
      "2017-10-29 18:48:17 Iter 800: batch trn loss = 0.061, accuracy = 0.980\n",
      "Epoch 0: mean loss = 0.105, accuracy = 0.962\n",
      "2017-10-29 18:48:49 Iter 900: batch trn loss = 0.059, accuracy = 0.980\n",
      "2017-10-29 18:49:21 Iter 1000: batch trn loss = 0.180, accuracy = 0.900\n",
      "2017-10-29 18:49:53 Iter 1100: batch trn loss = 0.089, accuracy = 0.960\n",
      "2017-10-29 18:50:25 Iter 1200: batch trn loss = 0.121, accuracy = 0.940\n",
      "2017-10-29 18:50:57 Iter 1300: batch trn loss = 0.042, accuracy = 0.980\n",
      "2017-10-29 18:51:29 Iter 1400: batch trn loss = 0.108, accuracy = 0.960\n",
      "2017-10-29 18:52:01 Iter 1500: batch trn loss = 0.130, accuracy = 0.960\n",
      "2017-10-29 18:52:32 Iter 1600: batch trn loss = 0.224, accuracy = 0.920\n",
      "2017-10-29 18:53:04 Iter 1700: batch trn loss = 0.167, accuracy = 0.920\n",
      "Epoch 1: mean loss = 0.101, accuracy = 0.963\n",
      "2017-10-29 18:53:36 Iter 1800: batch trn loss = 0.076, accuracy = 0.980\n",
      "2017-10-29 18:54:08 Iter 1900: batch trn loss = 0.044, accuracy = 0.980\n",
      "2017-10-29 18:54:40 Iter 2000: batch trn loss = 0.108, accuracy = 0.980\n",
      "2017-10-29 18:55:12 Iter 2100: batch trn loss = 0.016, accuracy = 1.000\n",
      "2017-10-29 18:55:44 Iter 2200: batch trn loss = 0.094, accuracy = 0.960\n",
      "2017-10-29 18:56:16 Iter 2300: batch trn loss = 0.130, accuracy = 0.960\n",
      "2017-10-29 18:56:48 Iter 2400: batch trn loss = 0.034, accuracy = 1.000\n",
      "2017-10-29 18:57:20 Iter 2500: batch trn loss = 0.229, accuracy = 0.900\n",
      "2017-10-29 18:57:52 Iter 2600: batch trn loss = 0.243, accuracy = 0.920\n",
      "Epoch 2: mean loss = 0.095, accuracy = 0.967\n",
      "2017-10-29 18:58:24 Iter 2700: batch trn loss = 0.167, accuracy = 0.960\n",
      "2017-10-29 18:58:55 Iter 2800: batch trn loss = 0.119, accuracy = 0.940\n",
      "2017-10-29 18:59:27 Iter 2900: batch trn loss = 0.032, accuracy = 1.000\n",
      "2017-10-29 18:59:59 Iter 3000: batch trn loss = 0.056, accuracy = 0.980\n",
      "2017-10-29 19:00:31 Iter 3100: batch trn loss = 0.096, accuracy = 0.980\n",
      "2017-10-29 19:01:03 Iter 3200: batch trn loss = 0.059, accuracy = 0.960\n",
      "2017-10-29 19:01:35 Iter 3300: batch trn loss = 0.062, accuracy = 1.000\n",
      "2017-10-29 19:02:07 Iter 3400: batch trn loss = 0.237, accuracy = 0.920\n",
      "2017-10-29 19:02:38 Iter 3500: batch trn loss = 0.114, accuracy = 0.980\n",
      "Epoch 3: mean loss = 0.092, accuracy = 0.967\n",
      "2017-10-29 19:03:10 Iter 3600: batch trn loss = 0.162, accuracy = 0.920\n",
      "2017-10-29 19:03:42 Iter 3700: batch trn loss = 0.106, accuracy = 0.960\n",
      "2017-10-29 19:04:14 Iter 3800: batch trn loss = 0.075, accuracy = 0.960\n",
      "2017-10-29 19:04:46 Iter 3900: batch trn loss = 0.159, accuracy = 0.960\n",
      "2017-10-29 19:05:18 Iter 4000: batch trn loss = 0.040, accuracy = 1.000\n",
      "2017-10-29 19:05:50 Iter 4100: batch trn loss = 0.164, accuracy = 0.940\n",
      "2017-10-29 19:06:21 Iter 4200: batch trn loss = 0.050, accuracy = 1.000\n",
      "2017-10-29 19:06:53 Iter 4300: batch trn loss = 0.010, accuracy = 1.000\n",
      "2017-10-29 19:07:25 Iter 4400: batch trn loss = 0.145, accuracy = 0.920\n",
      "Epoch 4: mean loss = 0.086, accuracy = 0.970\n",
      "validation\n",
      "Epoch 0: mean loss = 0.881, accuracy = 0.799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.88099295, 0.7994)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 35 epochs\n",
    "print('train')\n",
    "cnn.train(m_X_trn, y_trn, epochs=5, batch_size=50, print_every=100, plot_losses=False)\n",
    "print('validation')\n",
    "cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [110] Base + Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "def model_fn(layer_input, labels, is_training):\n",
    "    F1 = 32\n",
    "    layer = tf.layers.conv2d(inputs=layer_input, filters=F1, kernel_size=[5, 5], padding='same', activation=tf.nn.relu)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    F2 = 64\n",
    "    layer = tf.layers.conv2d(inputs=layer, filters=F2, kernel_size=[5, 5], padding='same', activation=tf.nn.relu)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    flat_size = int(H / 4 * W / 4 * F2)\n",
    "    print(flat_size)\n",
    "    layer = tf.reshape(layer, [-1, flat_size])\n",
    "    layer = tf.layers.dense(inputs=layer, units=1024)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer_logit = tf.layers.dense(inputs=layer, units=T)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int64), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=layer_logit)\n",
    "    return layer_logit, loss\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "cnn = CNN(model_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: epoch 0\n",
      "2017-10-29 22:46:42 Iter 0: batch trn loss = 3.061, accuracy = 0.120\n",
      "2017-10-29 22:47:02 Iter 100: batch trn loss = 1.623, accuracy = 0.520\n",
      "2017-10-29 22:47:22 Iter 200: batch trn loss = 1.551, accuracy = 0.440\n",
      "2017-10-29 22:47:42 Iter 300: batch trn loss = 1.611, accuracy = 0.480\n",
      "2017-10-29 22:48:02 Iter 400: batch trn loss = 0.991, accuracy = 0.680\n",
      "2017-10-29 22:48:21 Iter 500: batch trn loss = 1.343, accuracy = 0.520\n",
      "2017-10-29 22:48:42 Iter 600: batch trn loss = 1.673, accuracy = 0.360\n",
      "2017-10-29 22:49:02 Iter 700: batch trn loss = 1.418, accuracy = 0.560\n",
      "2017-10-29 22:49:22 Iter 800: batch trn loss = 1.172, accuracy = 0.560\n",
      "Epoch 0: mean loss = 1.384, accuracy = 0.543\n",
      "validation\n",
      "Epoch 0: mean loss = 1.108, accuracy = 0.624\n",
      "train: epoch 1\n",
      "2017-10-29 22:49:50 Iter 0: batch trn loss = 0.684, accuracy = 0.740\n",
      "2017-10-29 22:50:10 Iter 100: batch trn loss = 1.314, accuracy = 0.580\n",
      "2017-10-29 22:50:30 Iter 200: batch trn loss = 1.099, accuracy = 0.660\n",
      "2017-10-29 22:50:50 Iter 300: batch trn loss = 0.797, accuracy = 0.720\n",
      "2017-10-29 22:51:11 Iter 400: batch trn loss = 0.655, accuracy = 0.760\n",
      "2017-10-29 22:51:31 Iter 500: batch trn loss = 1.101, accuracy = 0.660\n",
      "2017-10-29 22:51:51 Iter 600: batch trn loss = 1.007, accuracy = 0.640\n",
      "2017-10-29 22:52:11 Iter 700: batch trn loss = 0.884, accuracy = 0.740\n",
      "2017-10-29 22:52:30 Iter 800: batch trn loss = 0.940, accuracy = 0.720\n",
      "Epoch 0: mean loss = 0.957, accuracy = 0.670\n",
      "validation\n",
      "Epoch 0: mean loss = 1.007, accuracy = 0.665\n",
      "train: epoch 2\n",
      "2017-10-29 22:52:58 Iter 0: batch trn loss = 0.773, accuracy = 0.680\n",
      "2017-10-29 22:53:19 Iter 100: batch trn loss = 0.727, accuracy = 0.760\n",
      "2017-10-29 22:53:39 Iter 200: batch trn loss = 0.948, accuracy = 0.680\n",
      "2017-10-29 22:53:59 Iter 300: batch trn loss = 0.876, accuracy = 0.700\n",
      "2017-10-29 22:54:19 Iter 400: batch trn loss = 0.801, accuracy = 0.760\n",
      "2017-10-29 22:54:40 Iter 500: batch trn loss = 0.858, accuracy = 0.720\n",
      "2017-10-29 22:54:59 Iter 600: batch trn loss = 0.666, accuracy = 0.800\n",
      "2017-10-29 22:55:19 Iter 700: batch trn loss = 0.675, accuracy = 0.740\n",
      "2017-10-29 22:55:39 Iter 800: batch trn loss = 0.676, accuracy = 0.760\n",
      "Epoch 0: mean loss = 0.824, accuracy = 0.717\n",
      "validation\n",
      "Epoch 0: mean loss = 0.980, accuracy = 0.686\n",
      "train: epoch 3\n",
      "2017-10-29 22:56:07 Iter 0: batch trn loss = 0.966, accuracy = 0.760\n",
      "2017-10-29 22:56:27 Iter 100: batch trn loss = 0.798, accuracy = 0.800\n",
      "2017-10-29 22:56:46 Iter 200: batch trn loss = 0.641, accuracy = 0.820\n",
      "2017-10-29 22:57:06 Iter 300: batch trn loss = 0.409, accuracy = 0.880\n",
      "2017-10-29 22:57:26 Iter 400: batch trn loss = 0.627, accuracy = 0.740\n",
      "2017-10-29 22:57:46 Iter 500: batch trn loss = 0.917, accuracy = 0.700\n",
      "2017-10-29 22:58:05 Iter 600: batch trn loss = 0.589, accuracy = 0.780\n",
      "2017-10-29 22:58:25 Iter 700: batch trn loss = 0.597, accuracy = 0.840\n",
      "2017-10-29 22:58:45 Iter 800: batch trn loss = 0.682, accuracy = 0.740\n",
      "Epoch 0: mean loss = 0.728, accuracy = 0.750\n",
      "validation\n",
      "Epoch 0: mean loss = 0.878, accuracy = 0.714\n",
      "train: epoch 4\n",
      "2017-10-29 22:59:14 Iter 0: batch trn loss = 0.685, accuracy = 0.760\n",
      "2017-10-29 22:59:34 Iter 100: batch trn loss = 0.525, accuracy = 0.820\n",
      "2017-10-29 22:59:54 Iter 200: batch trn loss = 0.664, accuracy = 0.760\n",
      "2017-10-29 23:00:13 Iter 300: batch trn loss = 0.825, accuracy = 0.740\n",
      "2017-10-29 23:00:33 Iter 400: batch trn loss = 0.745, accuracy = 0.800\n",
      "2017-10-29 23:00:52 Iter 500: batch trn loss = 0.599, accuracy = 0.840\n",
      "2017-10-29 23:01:12 Iter 600: batch trn loss = 0.558, accuracy = 0.820\n",
      "2017-10-29 23:01:32 Iter 700: batch trn loss = 0.797, accuracy = 0.720\n",
      "2017-10-29 23:01:51 Iter 800: batch trn loss = 0.555, accuracy = 0.840\n",
      "Epoch 0: mean loss = 0.657, accuracy = 0.774\n",
      "validation\n",
      "Epoch 0: mean loss = 0.965, accuracy = 0.694\n",
      "train: epoch 5\n",
      "2017-10-29 23:02:19 Iter 0: batch trn loss = 0.271, accuracy = 0.920\n",
      "2017-10-29 23:02:39 Iter 100: batch trn loss = 0.616, accuracy = 0.800\n",
      "2017-10-29 23:02:58 Iter 200: batch trn loss = 0.559, accuracy = 0.800\n",
      "2017-10-29 23:03:18 Iter 300: batch trn loss = 0.415, accuracy = 0.780\n",
      "2017-10-29 23:03:37 Iter 400: batch trn loss = 0.594, accuracy = 0.740\n",
      "2017-10-29 23:03:57 Iter 500: batch trn loss = 0.417, accuracy = 0.820\n",
      "2017-10-29 23:04:17 Iter 600: batch trn loss = 0.697, accuracy = 0.800\n",
      "2017-10-29 23:04:36 Iter 700: batch trn loss = 0.672, accuracy = 0.840\n",
      "2017-10-29 23:04:56 Iter 800: batch trn loss = 0.763, accuracy = 0.800\n",
      "Epoch 0: mean loss = 0.597, accuracy = 0.794\n",
      "validation\n",
      "Epoch 0: mean loss = 0.939, accuracy = 0.702\n",
      "train: epoch 6\n",
      "2017-10-29 23:05:24 Iter 0: batch trn loss = 0.619, accuracy = 0.840\n",
      "2017-10-29 23:05:43 Iter 100: batch trn loss = 0.524, accuracy = 0.780\n",
      "2017-10-29 23:06:03 Iter 200: batch trn loss = 0.551, accuracy = 0.780\n",
      "2017-10-29 23:06:22 Iter 300: batch trn loss = 0.551, accuracy = 0.780\n",
      "2017-10-29 23:06:42 Iter 400: batch trn loss = 0.450, accuracy = 0.820\n",
      "2017-10-29 23:07:02 Iter 500: batch trn loss = 0.546, accuracy = 0.820\n",
      "2017-10-29 23:07:21 Iter 600: batch trn loss = 0.445, accuracy = 0.900\n",
      "2017-10-29 23:07:41 Iter 700: batch trn loss = 0.363, accuracy = 0.780\n",
      "2017-10-29 23:08:00 Iter 800: batch trn loss = 0.601, accuracy = 0.780\n",
      "Epoch 0: mean loss = 0.540, accuracy = 0.812\n",
      "validation\n",
      "Epoch 0: mean loss = 0.972, accuracy = 0.707\n",
      "train: epoch 7\n",
      "2017-10-29 23:08:28 Iter 0: batch trn loss = 0.648, accuracy = 0.760\n",
      "2017-10-29 23:08:47 Iter 100: batch trn loss = 0.424, accuracy = 0.860\n",
      "2017-10-29 23:09:07 Iter 200: batch trn loss = 0.603, accuracy = 0.760\n",
      "2017-10-29 23:09:27 Iter 300: batch trn loss = 0.374, accuracy = 0.900\n",
      "2017-10-29 23:09:46 Iter 400: batch trn loss = 0.376, accuracy = 0.880\n",
      "2017-10-29 23:10:06 Iter 500: batch trn loss = 0.759, accuracy = 0.760\n",
      "2017-10-29 23:10:26 Iter 600: batch trn loss = 0.476, accuracy = 0.820\n",
      "2017-10-29 23:10:45 Iter 700: batch trn loss = 0.566, accuracy = 0.760\n",
      "2017-10-29 23:11:05 Iter 800: batch trn loss = 0.576, accuracy = 0.820\n",
      "Epoch 0: mean loss = 0.500, accuracy = 0.824\n",
      "validation\n",
      "Epoch 0: mean loss = 0.969, accuracy = 0.714\n",
      "train: epoch 8\n",
      "2017-10-29 23:11:33 Iter 0: batch trn loss = 0.259, accuracy = 0.940\n",
      "2017-10-29 23:11:54 Iter 100: batch trn loss = 0.291, accuracy = 0.860\n",
      "2017-10-29 23:12:15 Iter 200: batch trn loss = 0.379, accuracy = 0.880\n",
      "2017-10-29 23:12:36 Iter 300: batch trn loss = 0.325, accuracy = 0.920\n",
      "2017-10-29 23:12:56 Iter 400: batch trn loss = 0.449, accuracy = 0.880\n",
      "2017-10-29 23:13:17 Iter 500: batch trn loss = 0.522, accuracy = 0.800\n",
      "2017-10-29 23:13:36 Iter 600: batch trn loss = 0.507, accuracy = 0.820\n",
      "2017-10-29 23:13:56 Iter 700: batch trn loss = 0.682, accuracy = 0.780\n",
      "2017-10-29 23:14:16 Iter 800: batch trn loss = 0.405, accuracy = 0.860\n",
      "Epoch 0: mean loss = 0.453, accuracy = 0.842\n",
      "validation\n",
      "Epoch 0: mean loss = 1.009, accuracy = 0.704\n",
      "train: epoch 9\n",
      "2017-10-29 23:14:44 Iter 0: batch trn loss = 0.341, accuracy = 0.840\n",
      "2017-10-29 23:15:05 Iter 100: batch trn loss = 0.361, accuracy = 0.860\n",
      "2017-10-29 23:15:25 Iter 200: batch trn loss = 0.294, accuracy = 0.900\n",
      "2017-10-29 23:15:45 Iter 300: batch trn loss = 0.486, accuracy = 0.860\n",
      "2017-10-29 23:16:05 Iter 400: batch trn loss = 0.375, accuracy = 0.860\n",
      "2017-10-29 23:16:26 Iter 500: batch trn loss = 0.517, accuracy = 0.820\n",
      "2017-10-29 23:16:46 Iter 600: batch trn loss = 0.332, accuracy = 0.900\n",
      "2017-10-29 23:17:07 Iter 700: batch trn loss = 0.365, accuracy = 0.820\n",
      "2017-10-29 23:17:27 Iter 800: batch trn loss = 0.387, accuracy = 0.860\n",
      "Epoch 0: mean loss = 0.413, accuracy = 0.853\n",
      "validation\n",
      "Epoch 0: mean loss = 1.090, accuracy = 0.701\n",
      "train: epoch 10\n",
      "2017-10-29 23:17:55 Iter 0: batch trn loss = 0.439, accuracy = 0.880\n",
      "2017-10-29 23:18:16 Iter 100: batch trn loss = 0.368, accuracy = 0.860\n",
      "2017-10-29 23:18:36 Iter 200: batch trn loss = 0.366, accuracy = 0.820\n",
      "2017-10-29 23:18:57 Iter 300: batch trn loss = 0.342, accuracy = 0.860\n",
      "2017-10-29 23:19:17 Iter 400: batch trn loss = 0.221, accuracy = 0.920\n",
      "2017-10-29 23:19:38 Iter 500: batch trn loss = 0.464, accuracy = 0.840\n",
      "2017-10-29 23:19:58 Iter 600: batch trn loss = 0.344, accuracy = 0.840\n",
      "2017-10-29 23:20:19 Iter 700: batch trn loss = 0.633, accuracy = 0.860\n",
      "2017-10-29 23:20:39 Iter 800: batch trn loss = 0.215, accuracy = 0.940\n",
      "Epoch 0: mean loss = 0.377, accuracy = 0.867\n",
      "validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: mean loss = 1.168, accuracy = 0.702\n",
      "train: epoch 11\n",
      "2017-10-29 23:21:08 Iter 0: batch trn loss = 0.373, accuracy = 0.840\n",
      "2017-10-29 23:21:29 Iter 100: batch trn loss = 0.208, accuracy = 0.920\n",
      "2017-10-29 23:21:50 Iter 200: batch trn loss = 0.293, accuracy = 0.880\n",
      "2017-10-29 23:22:10 Iter 300: batch trn loss = 0.270, accuracy = 0.920\n",
      "2017-10-29 23:22:30 Iter 400: batch trn loss = 0.395, accuracy = 0.840\n",
      "2017-10-29 23:22:51 Iter 500: batch trn loss = 0.489, accuracy = 0.800\n",
      "2017-10-29 23:23:11 Iter 600: batch trn loss = 0.256, accuracy = 0.940\n",
      "2017-10-29 23:23:32 Iter 700: batch trn loss = 0.250, accuracy = 0.900\n",
      "2017-10-29 23:23:53 Iter 800: batch trn loss = 0.560, accuracy = 0.820\n",
      "Epoch 0: mean loss = 0.351, accuracy = 0.876\n",
      "validation\n",
      "Epoch 0: mean loss = 1.197, accuracy = 0.702\n",
      "train: epoch 12\n",
      "2017-10-29 23:24:21 Iter 0: batch trn loss = 0.140, accuracy = 0.960\n",
      "2017-10-29 23:24:42 Iter 100: batch trn loss = 0.371, accuracy = 0.900\n",
      "2017-10-29 23:25:02 Iter 200: batch trn loss = 0.338, accuracy = 0.860\n",
      "2017-10-29 23:25:22 Iter 300: batch trn loss = 0.274, accuracy = 0.940\n",
      "2017-10-29 23:25:43 Iter 400: batch trn loss = 0.126, accuracy = 0.960\n",
      "2017-10-29 23:26:04 Iter 500: batch trn loss = 0.357, accuracy = 0.900\n",
      "2017-10-29 23:26:24 Iter 600: batch trn loss = 0.442, accuracy = 0.860\n",
      "2017-10-29 23:26:44 Iter 700: batch trn loss = 0.308, accuracy = 0.860\n",
      "2017-10-29 23:27:05 Iter 800: batch trn loss = 0.398, accuracy = 0.860\n",
      "Epoch 0: mean loss = 0.323, accuracy = 0.883\n",
      "validation\n",
      "Epoch 0: mean loss = 1.219, accuracy = 0.694\n",
      "train: epoch 13\n",
      "2017-10-29 23:27:33 Iter 0: batch trn loss = 0.249, accuracy = 0.900\n",
      "2017-10-29 23:27:53 Iter 100: batch trn loss = 0.169, accuracy = 0.920\n",
      "2017-10-29 23:28:13 Iter 200: batch trn loss = 0.343, accuracy = 0.880\n",
      "2017-10-29 23:28:32 Iter 300: batch trn loss = 0.292, accuracy = 0.880\n",
      "2017-10-29 23:28:52 Iter 400: batch trn loss = 0.337, accuracy = 0.880\n",
      "2017-10-29 23:29:12 Iter 500: batch trn loss = 0.368, accuracy = 0.860\n",
      "2017-10-29 23:29:31 Iter 600: batch trn loss = 0.570, accuracy = 0.820\n",
      "2017-10-29 23:29:52 Iter 700: batch trn loss = 0.233, accuracy = 0.880\n",
      "2017-10-29 23:30:12 Iter 800: batch trn loss = 0.270, accuracy = 0.920\n",
      "Epoch 0: mean loss = 0.294, accuracy = 0.895\n",
      "validation\n",
      "Epoch 0: mean loss = 1.244, accuracy = 0.702\n",
      "train: epoch 14\n",
      "2017-10-29 23:30:41 Iter 0: batch trn loss = 0.265, accuracy = 0.880\n",
      "2017-10-29 23:31:02 Iter 100: batch trn loss = 0.219, accuracy = 0.940\n",
      "2017-10-29 23:31:22 Iter 200: batch trn loss = 0.314, accuracy = 0.900\n",
      "2017-10-29 23:31:44 Iter 300: batch trn loss = 0.308, accuracy = 0.900\n",
      "2017-10-29 23:32:05 Iter 400: batch trn loss = 0.307, accuracy = 0.880\n",
      "2017-10-29 23:32:25 Iter 500: batch trn loss = 0.219, accuracy = 0.940\n",
      "2017-10-29 23:32:45 Iter 600: batch trn loss = 0.402, accuracy = 0.820\n",
      "2017-10-29 23:33:06 Iter 700: batch trn loss = 0.202, accuracy = 0.920\n",
      "2017-10-29 23:33:26 Iter 800: batch trn loss = 0.284, accuracy = 0.840\n",
      "Epoch 0: mean loss = 0.275, accuracy = 0.902\n",
      "validation\n",
      "Epoch 0: mean loss = 1.313, accuracy = 0.710\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('train: epoch %d' % i)\n",
    "    cnn.train(m_X_trn, y_trn, epochs=1, batch_size=50, print_every=100, plot_losses=False)\n",
    "    print('validation')\n",
    "    cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0111]\n",
    "- base (0110)\n",
    "- add l2 regularization 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "def model_fn(layer_input, labels, is_training):\n",
    "    reg_scale= 0.1\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=reg_scale)\n",
    "    F1 = 32\n",
    "    layer = tf.layers.conv2d(inputs=layer_input, filters=F1, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, \n",
    "                             kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    F2 = 64\n",
    "    layer = tf.layers.conv2d(inputs=layer, filters=F2, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "                            kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    flat_size = int(H / 4 * W / 4 * F2)\n",
    "    print(flat_size)\n",
    "    layer = tf.reshape(layer, [-1, flat_size])\n",
    "    layer = tf.layers.dense(inputs=layer, units=1024,\n",
    "                           kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer_logit = tf.layers.dense(inputs=layer, units=T,\n",
    "                                 kernel_regularizer=regularizer)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int64), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=layer_logit)\n",
    "    return layer_logit, loss\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "cnn = CNN(model_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: epoch 0\n",
      "2017-10-29 23:36:22 Iter 0: batch trn loss = 2.905, accuracy = 0.080\n",
      "2017-10-29 23:36:44 Iter 100: batch trn loss = 2.114, accuracy = 0.340\n",
      "2017-10-29 23:37:04 Iter 200: batch trn loss = 1.560, accuracy = 0.480\n",
      "2017-10-29 23:37:23 Iter 300: batch trn loss = 1.249, accuracy = 0.500\n",
      "2017-10-29 23:37:43 Iter 400: batch trn loss = 1.528, accuracy = 0.420\n",
      "2017-10-29 23:38:03 Iter 500: batch trn loss = 1.413, accuracy = 0.500\n",
      "2017-10-29 23:38:23 Iter 600: batch trn loss = 1.186, accuracy = 0.640\n",
      "2017-10-29 23:38:42 Iter 700: batch trn loss = 1.071, accuracy = 0.680\n",
      "2017-10-29 23:39:02 Iter 800: batch trn loss = 1.012, accuracy = 0.660\n",
      "Epoch 0: mean loss = 1.389, accuracy = 0.546\n",
      "validation\n",
      "Epoch 0: mean loss = 1.060, accuracy = 0.633\n",
      "train: epoch 1\n",
      "2017-10-29 23:39:30 Iter 0: batch trn loss = 0.806, accuracy = 0.680\n",
      "2017-10-29 23:39:50 Iter 100: batch trn loss = 0.926, accuracy = 0.680\n",
      "2017-10-29 23:40:10 Iter 200: batch trn loss = 1.099, accuracy = 0.640\n",
      "2017-10-29 23:40:29 Iter 300: batch trn loss = 0.814, accuracy = 0.720\n",
      "2017-10-29 23:40:49 Iter 400: batch trn loss = 0.640, accuracy = 0.760\n",
      "2017-10-29 23:41:09 Iter 500: batch trn loss = 1.007, accuracy = 0.740\n",
      "2017-10-29 23:41:29 Iter 600: batch trn loss = 0.713, accuracy = 0.760\n",
      "2017-10-29 23:41:48 Iter 700: batch trn loss = 0.933, accuracy = 0.640\n",
      "2017-10-29 23:42:08 Iter 800: batch trn loss = 0.955, accuracy = 0.680\n",
      "Epoch 0: mean loss = 0.964, accuracy = 0.671\n",
      "validation\n",
      "Epoch 0: mean loss = 0.986, accuracy = 0.664\n",
      "train: epoch 2\n",
      "2017-10-29 23:42:40 Iter 0: batch trn loss = 0.806, accuracy = 0.700\n",
      "2017-10-29 23:43:01 Iter 100: batch trn loss = 0.843, accuracy = 0.680\n",
      "2017-10-29 23:43:21 Iter 200: batch trn loss = 1.252, accuracy = 0.560\n",
      "2017-10-29 23:43:41 Iter 300: batch trn loss = 0.728, accuracy = 0.720\n",
      "2017-10-29 23:44:03 Iter 400: batch trn loss = 0.909, accuracy = 0.620\n",
      "2017-10-29 23:44:24 Iter 500: batch trn loss = 0.767, accuracy = 0.740\n",
      "2017-10-29 23:44:45 Iter 600: batch trn loss = 0.926, accuracy = 0.720\n",
      "2017-10-29 23:45:05 Iter 700: batch trn loss = 0.777, accuracy = 0.720\n",
      "2017-10-29 23:45:27 Iter 800: batch trn loss = 0.911, accuracy = 0.780\n",
      "Epoch 0: mean loss = 0.831, accuracy = 0.714\n",
      "validation\n",
      "Epoch 0: mean loss = 0.961, accuracy = 0.681\n",
      "train: epoch 3\n",
      "2017-10-29 23:45:55 Iter 0: batch trn loss = 0.800, accuracy = 0.740\n",
      "2017-10-29 23:46:15 Iter 100: batch trn loss = 0.664, accuracy = 0.760\n",
      "2017-10-29 23:46:36 Iter 200: batch trn loss = 0.809, accuracy = 0.680\n",
      "2017-10-29 23:46:57 Iter 300: batch trn loss = 0.926, accuracy = 0.680\n",
      "2017-10-29 23:47:17 Iter 400: batch trn loss = 0.381, accuracy = 0.840\n",
      "2017-10-29 23:47:37 Iter 500: batch trn loss = 0.479, accuracy = 0.840\n",
      "2017-10-29 23:47:57 Iter 600: batch trn loss = 0.639, accuracy = 0.740\n",
      "2017-10-29 23:48:18 Iter 700: batch trn loss = 0.527, accuracy = 0.840\n",
      "2017-10-29 23:48:39 Iter 800: batch trn loss = 0.809, accuracy = 0.720\n",
      "Epoch 0: mean loss = 0.734, accuracy = 0.748\n",
      "validation\n",
      "Epoch 0: mean loss = 1.039, accuracy = 0.663\n",
      "train: epoch 4\n",
      "2017-10-29 23:49:08 Iter 0: batch trn loss = 0.740, accuracy = 0.760\n",
      "2017-10-29 23:49:29 Iter 100: batch trn loss = 0.479, accuracy = 0.780\n",
      "2017-10-29 23:49:50 Iter 200: batch trn loss = 0.806, accuracy = 0.680\n",
      "2017-10-29 23:50:10 Iter 300: batch trn loss = 0.679, accuracy = 0.800\n",
      "2017-10-29 23:50:30 Iter 400: batch trn loss = 0.616, accuracy = 0.800\n",
      "2017-10-29 23:50:50 Iter 500: batch trn loss = 0.493, accuracy = 0.740\n",
      "2017-10-29 23:51:10 Iter 600: batch trn loss = 0.655, accuracy = 0.800\n",
      "2017-10-29 23:51:30 Iter 700: batch trn loss = 0.606, accuracy = 0.800\n",
      "2017-10-29 23:51:50 Iter 800: batch trn loss = 0.488, accuracy = 0.780\n",
      "Epoch 0: mean loss = 0.656, accuracy = 0.773\n",
      "validation\n",
      "Epoch 0: mean loss = 0.967, accuracy = 0.692\n",
      "train: epoch 5\n",
      "2017-10-29 23:52:18 Iter 0: batch trn loss = 0.433, accuracy = 0.860\n",
      "2017-10-29 23:52:38 Iter 100: batch trn loss = 0.500, accuracy = 0.840\n",
      "2017-10-29 23:52:58 Iter 200: batch trn loss = 0.553, accuracy = 0.800\n",
      "2017-10-29 23:53:18 Iter 300: batch trn loss = 0.752, accuracy = 0.800\n",
      "2017-10-29 23:53:37 Iter 400: batch trn loss = 0.439, accuracy = 0.860\n",
      "2017-10-29 23:53:57 Iter 500: batch trn loss = 0.593, accuracy = 0.800\n",
      "2017-10-29 23:54:17 Iter 600: batch trn loss = 0.705, accuracy = 0.720\n",
      "2017-10-29 23:54:37 Iter 700: batch trn loss = 0.645, accuracy = 0.780\n",
      "2017-10-29 23:54:57 Iter 800: batch trn loss = 0.847, accuracy = 0.700\n",
      "Epoch 0: mean loss = 0.601, accuracy = 0.791\n",
      "validation\n",
      "Epoch 0: mean loss = 0.937, accuracy = 0.710\n",
      "train: epoch 6\n",
      "2017-10-29 23:55:25 Iter 0: batch trn loss = 0.483, accuracy = 0.860\n",
      "2017-10-29 23:55:45 Iter 100: batch trn loss = 0.685, accuracy = 0.800\n",
      "2017-10-29 23:56:05 Iter 200: batch trn loss = 0.872, accuracy = 0.780\n",
      "2017-10-29 23:56:25 Iter 300: batch trn loss = 0.415, accuracy = 0.900\n",
      "2017-10-29 23:56:45 Iter 400: batch trn loss = 0.451, accuracy = 0.860\n",
      "2017-10-29 23:57:04 Iter 500: batch trn loss = 0.649, accuracy = 0.800\n",
      "2017-10-29 23:57:24 Iter 600: batch trn loss = 0.670, accuracy = 0.740\n",
      "2017-10-29 23:57:44 Iter 700: batch trn loss = 0.460, accuracy = 0.840\n",
      "2017-10-29 23:58:05 Iter 800: batch trn loss = 0.942, accuracy = 0.760\n",
      "Epoch 0: mean loss = 0.541, accuracy = 0.813\n",
      "validation\n",
      "Epoch 0: mean loss = 0.979, accuracy = 0.702\n",
      "train: epoch 7\n",
      "2017-10-29 23:58:35 Iter 0: batch trn loss = 0.479, accuracy = 0.840\n",
      "2017-10-29 23:58:55 Iter 100: batch trn loss = 0.287, accuracy = 0.900\n",
      "2017-10-29 23:59:15 Iter 200: batch trn loss = 0.307, accuracy = 0.860\n",
      "2017-10-29 23:59:34 Iter 300: batch trn loss = 0.495, accuracy = 0.860\n",
      "2017-10-29 23:59:54 Iter 400: batch trn loss = 0.454, accuracy = 0.800\n",
      "2017-10-30 00:00:14 Iter 500: batch trn loss = 0.660, accuracy = 0.760\n",
      "2017-10-30 00:00:34 Iter 600: batch trn loss = 0.400, accuracy = 0.880\n",
      "2017-10-30 00:00:54 Iter 700: batch trn loss = 0.271, accuracy = 0.900\n",
      "2017-10-30 00:01:14 Iter 800: batch trn loss = 0.576, accuracy = 0.820\n",
      "Epoch 0: mean loss = 0.492, accuracy = 0.829\n",
      "validation\n",
      "Epoch 0: mean loss = 1.027, accuracy = 0.693\n",
      "train: epoch 8\n",
      "2017-10-30 00:01:41 Iter 0: batch trn loss = 0.226, accuracy = 0.920\n",
      "2017-10-30 00:02:01 Iter 100: batch trn loss = 0.325, accuracy = 0.880\n",
      "2017-10-30 00:02:21 Iter 200: batch trn loss = 0.458, accuracy = 0.860\n",
      "2017-10-30 00:02:42 Iter 300: batch trn loss = 0.404, accuracy = 0.840\n",
      "2017-10-30 00:03:04 Iter 400: batch trn loss = 0.379, accuracy = 0.880\n",
      "2017-10-30 00:03:24 Iter 500: batch trn loss = 0.417, accuracy = 0.880\n",
      "2017-10-30 00:03:45 Iter 600: batch trn loss = 0.603, accuracy = 0.740\n",
      "2017-10-30 00:04:05 Iter 700: batch trn loss = 0.385, accuracy = 0.820\n",
      "2017-10-30 00:04:25 Iter 800: batch trn loss = 0.584, accuracy = 0.840\n",
      "Epoch 0: mean loss = 0.449, accuracy = 0.844\n",
      "validation\n",
      "Epoch 0: mean loss = 1.080, accuracy = 0.691\n",
      "train: epoch 9\n",
      "2017-10-30 00:04:54 Iter 0: batch trn loss = 0.338, accuracy = 0.900\n",
      "2017-10-30 00:05:15 Iter 100: batch trn loss = 0.440, accuracy = 0.840\n",
      "2017-10-30 00:05:36 Iter 200: batch trn loss = 0.335, accuracy = 0.840\n",
      "2017-10-30 00:05:56 Iter 300: batch trn loss = 0.344, accuracy = 0.880\n",
      "2017-10-30 00:06:17 Iter 400: batch trn loss = 0.466, accuracy = 0.880\n",
      "2017-10-30 00:06:37 Iter 500: batch trn loss = 0.454, accuracy = 0.800\n",
      "2017-10-30 00:06:58 Iter 600: batch trn loss = 0.136, accuracy = 0.960\n",
      "2017-10-30 00:07:18 Iter 700: batch trn loss = 0.512, accuracy = 0.860\n",
      "2017-10-30 00:07:38 Iter 800: batch trn loss = 0.205, accuracy = 0.940\n",
      "Epoch 0: mean loss = 0.414, accuracy = 0.853\n",
      "validation\n",
      "Epoch 0: mean loss = 1.047, accuracy = 0.712\n",
      "train: epoch 10\n",
      "2017-10-30 00:08:08 Iter 0: batch trn loss = 0.322, accuracy = 0.900\n",
      "2017-10-30 00:08:28 Iter 100: batch trn loss = 0.223, accuracy = 0.900\n",
      "2017-10-30 00:08:48 Iter 200: batch trn loss = 0.303, accuracy = 0.920\n",
      "2017-10-30 00:09:08 Iter 300: batch trn loss = 0.472, accuracy = 0.900\n",
      "2017-10-30 00:09:29 Iter 400: batch trn loss = 0.371, accuracy = 0.840\n",
      "2017-10-30 00:09:50 Iter 500: batch trn loss = 0.402, accuracy = 0.880\n",
      "2017-10-30 00:10:11 Iter 600: batch trn loss = 0.698, accuracy = 0.800\n",
      "2017-10-30 00:10:32 Iter 700: batch trn loss = 0.377, accuracy = 0.900\n",
      "2017-10-30 00:10:52 Iter 800: batch trn loss = 0.457, accuracy = 0.840\n",
      "Epoch 0: mean loss = 0.376, accuracy = 0.867\n",
      "validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: mean loss = 1.212, accuracy = 0.685\n",
      "train: epoch 11\n",
      "2017-10-30 00:11:21 Iter 0: batch trn loss = 0.412, accuracy = 0.840\n",
      "2017-10-30 00:11:42 Iter 100: batch trn loss = 0.109, accuracy = 0.960\n",
      "2017-10-30 00:12:03 Iter 200: batch trn loss = 0.399, accuracy = 0.840\n",
      "2017-10-30 00:12:25 Iter 300: batch trn loss = 0.188, accuracy = 0.960\n",
      "2017-10-30 00:12:47 Iter 400: batch trn loss = 0.235, accuracy = 0.920\n",
      "2017-10-30 00:13:07 Iter 500: batch trn loss = 0.335, accuracy = 0.900\n",
      "2017-10-30 00:13:28 Iter 600: batch trn loss = 0.501, accuracy = 0.800\n",
      "2017-10-30 00:13:49 Iter 700: batch trn loss = 0.434, accuracy = 0.880\n",
      "2017-10-30 00:14:09 Iter 800: batch trn loss = 0.381, accuracy = 0.920\n",
      "Epoch 0: mean loss = 0.342, accuracy = 0.880\n",
      "validation\n",
      "Epoch 0: mean loss = 1.197, accuracy = 0.701\n",
      "train: epoch 12\n",
      "2017-10-30 00:14:38 Iter 0: batch trn loss = 0.363, accuracy = 0.860\n",
      "2017-10-30 00:14:59 Iter 100: batch trn loss = 0.208, accuracy = 0.900\n",
      "2017-10-30 00:15:20 Iter 200: batch trn loss = 0.307, accuracy = 0.900\n",
      "2017-10-30 00:15:41 Iter 300: batch trn loss = 0.336, accuracy = 0.860\n",
      "2017-10-30 00:16:02 Iter 400: batch trn loss = 0.313, accuracy = 0.860\n",
      "2017-10-30 00:16:22 Iter 500: batch trn loss = 0.338, accuracy = 0.900\n",
      "2017-10-30 00:16:43 Iter 600: batch trn loss = 0.334, accuracy = 0.900\n",
      "2017-10-30 00:17:03 Iter 700: batch trn loss = 0.258, accuracy = 0.880\n",
      "2017-10-30 00:17:22 Iter 800: batch trn loss = 0.480, accuracy = 0.840\n",
      "Epoch 0: mean loss = 0.318, accuracy = 0.887\n",
      "validation\n",
      "Epoch 0: mean loss = 1.198, accuracy = 0.695\n",
      "train: epoch 13\n",
      "2017-10-30 00:17:51 Iter 0: batch trn loss = 0.141, accuracy = 0.940\n",
      "2017-10-30 00:18:11 Iter 100: batch trn loss = 0.370, accuracy = 0.920\n",
      "2017-10-30 00:18:31 Iter 200: batch trn loss = 0.257, accuracy = 0.920\n",
      "2017-10-30 00:18:51 Iter 300: batch trn loss = 0.241, accuracy = 0.940\n",
      "2017-10-30 00:19:10 Iter 400: batch trn loss = 0.366, accuracy = 0.860\n",
      "2017-10-30 00:19:30 Iter 500: batch trn loss = 0.269, accuracy = 0.900\n",
      "2017-10-30 00:19:51 Iter 600: batch trn loss = 0.423, accuracy = 0.840\n",
      "2017-10-30 00:20:11 Iter 700: batch trn loss = 0.426, accuracy = 0.840\n",
      "2017-10-30 00:20:31 Iter 800: batch trn loss = 0.169, accuracy = 0.960\n",
      "Epoch 0: mean loss = 0.288, accuracy = 0.899\n",
      "validation\n",
      "Epoch 0: mean loss = 1.261, accuracy = 0.702\n",
      "train: epoch 14\n",
      "2017-10-30 00:20:59 Iter 0: batch trn loss = 0.178, accuracy = 0.920\n",
      "2017-10-30 00:21:20 Iter 100: batch trn loss = 0.477, accuracy = 0.820\n",
      "2017-10-30 00:21:40 Iter 200: batch trn loss = 0.258, accuracy = 0.920\n",
      "2017-10-30 00:22:00 Iter 300: batch trn loss = 0.202, accuracy = 0.940\n",
      "2017-10-30 00:22:21 Iter 400: batch trn loss = 0.143, accuracy = 0.960\n",
      "2017-10-30 00:22:43 Iter 500: batch trn loss = 0.242, accuracy = 0.900\n",
      "2017-10-30 00:23:03 Iter 600: batch trn loss = 0.098, accuracy = 0.960\n",
      "2017-10-30 00:23:22 Iter 700: batch trn loss = 0.159, accuracy = 0.940\n",
      "2017-10-30 00:23:42 Iter 800: batch trn loss = 0.473, accuracy = 0.860\n",
      "Epoch 0: mean loss = 0.278, accuracy = 0.899\n",
      "validation\n",
      "Epoch 0: mean loss = 1.343, accuracy = 0.689\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('train: epoch %d' % i)\n",
    "    cnn.train(m_X_trn, y_trn, epochs=1, batch_size=50, print_every=100, plot_losses=False)\n",
    "    print('validation')\n",
    "    cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0111.1]\n",
    "- reg 0.1 -> 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "def model_fn(layer_input, labels, is_training):\n",
    "    reg_scale= 1.0\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=reg_scale)\n",
    "    F1 = 32\n",
    "    layer = tf.layers.conv2d(inputs=layer_input, filters=F1, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, \n",
    "                             kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    F2 = 64\n",
    "    layer = tf.layers.conv2d(inputs=layer, filters=F2, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "                            kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    flat_size = int(H / 4 * W / 4 * F2)\n",
    "    print(flat_size)\n",
    "    layer = tf.reshape(layer, [-1, flat_size])\n",
    "    layer = tf.layers.dense(inputs=layer, units=1024,\n",
    "                           kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer_logit = tf.layers.dense(inputs=layer, units=T,\n",
    "                                 kernel_regularizer=regularizer)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int64), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=layer_logit)\n",
    "    return layer_logit, loss\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "cnn = CNN(model_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: epoch 0\n",
      "2017-10-30 00:25:00 Iter 0: batch trn loss = 2.890, accuracy = 0.140\n",
      "2017-10-30 00:25:20 Iter 100: batch trn loss = 1.105, accuracy = 0.640\n",
      "2017-10-30 00:25:40 Iter 200: batch trn loss = 1.890, accuracy = 0.360\n",
      "2017-10-30 00:26:00 Iter 300: batch trn loss = 0.996, accuracy = 0.640\n",
      "2017-10-30 00:26:20 Iter 400: batch trn loss = 1.493, accuracy = 0.520\n",
      "2017-10-30 00:26:40 Iter 500: batch trn loss = 1.468, accuracy = 0.520\n",
      "2017-10-30 00:27:01 Iter 600: batch trn loss = 1.331, accuracy = 0.460\n",
      "2017-10-30 00:27:22 Iter 700: batch trn loss = 1.409, accuracy = 0.580\n",
      "2017-10-30 00:27:42 Iter 800: batch trn loss = 0.965, accuracy = 0.640\n",
      "Epoch 0: mean loss = 1.403, accuracy = 0.536\n",
      "validation\n",
      "Epoch 0: mean loss = 1.170, accuracy = 0.597\n",
      "train: epoch 1\n",
      "2017-10-30 00:28:09 Iter 0: batch trn loss = 1.005, accuracy = 0.600\n",
      "2017-10-30 00:28:30 Iter 100: batch trn loss = 1.107, accuracy = 0.620\n",
      "2017-10-30 00:28:51 Iter 200: batch trn loss = 1.291, accuracy = 0.600\n",
      "2017-10-30 00:29:11 Iter 300: batch trn loss = 0.940, accuracy = 0.680\n",
      "2017-10-30 00:29:34 Iter 400: batch trn loss = 1.012, accuracy = 0.640\n",
      "2017-10-30 00:29:55 Iter 500: batch trn loss = 1.041, accuracy = 0.640\n",
      "2017-10-30 00:30:15 Iter 600: batch trn loss = 1.026, accuracy = 0.680\n",
      "2017-10-30 00:30:36 Iter 700: batch trn loss = 1.248, accuracy = 0.560\n",
      "2017-10-30 00:30:58 Iter 800: batch trn loss = 0.944, accuracy = 0.680\n",
      "Epoch 0: mean loss = 0.963, accuracy = 0.668\n",
      "validation\n",
      "Epoch 0: mean loss = 0.987, accuracy = 0.661\n",
      "train: epoch 2\n",
      "2017-10-30 00:31:26 Iter 0: batch trn loss = 0.701, accuracy = 0.740\n",
      "2017-10-30 00:31:45 Iter 100: batch trn loss = 0.929, accuracy = 0.660\n",
      "2017-10-30 00:32:05 Iter 200: batch trn loss = 0.708, accuracy = 0.760\n",
      "2017-10-30 00:32:25 Iter 300: batch trn loss = 0.593, accuracy = 0.760\n",
      "2017-10-30 00:32:45 Iter 400: batch trn loss = 0.921, accuracy = 0.660\n",
      "2017-10-30 00:33:05 Iter 500: batch trn loss = 0.769, accuracy = 0.680\n",
      "2017-10-30 00:33:25 Iter 600: batch trn loss = 0.992, accuracy = 0.680\n",
      "2017-10-30 00:33:46 Iter 700: batch trn loss = 0.915, accuracy = 0.680\n",
      "2017-10-30 00:34:06 Iter 800: batch trn loss = 0.901, accuracy = 0.640\n",
      "Epoch 0: mean loss = 0.820, accuracy = 0.717\n",
      "validation\n",
      "Epoch 0: mean loss = 0.989, accuracy = 0.672\n",
      "train: epoch 3\n",
      "2017-10-30 00:34:33 Iter 0: batch trn loss = 0.537, accuracy = 0.800\n",
      "2017-10-30 00:34:53 Iter 100: batch trn loss = 0.663, accuracy = 0.820\n",
      "2017-10-30 00:35:13 Iter 200: batch trn loss = 1.112, accuracy = 0.640\n",
      "2017-10-30 00:35:33 Iter 300: batch trn loss = 0.624, accuracy = 0.760\n",
      "2017-10-30 00:35:52 Iter 400: batch trn loss = 0.895, accuracy = 0.680\n",
      "2017-10-30 00:36:12 Iter 500: batch trn loss = 0.561, accuracy = 0.800\n",
      "2017-10-30 00:36:32 Iter 600: batch trn loss = 1.095, accuracy = 0.700\n",
      "2017-10-30 00:36:51 Iter 700: batch trn loss = 0.882, accuracy = 0.660\n",
      "2017-10-30 00:37:11 Iter 800: batch trn loss = 0.472, accuracy = 0.820\n",
      "Epoch 0: mean loss = 0.735, accuracy = 0.748\n",
      "validation\n",
      "Epoch 0: mean loss = 0.936, accuracy = 0.691\n",
      "train: epoch 4\n",
      "2017-10-30 00:37:39 Iter 0: batch trn loss = 0.463, accuracy = 0.840\n",
      "2017-10-30 00:37:59 Iter 100: batch trn loss = 0.415, accuracy = 0.840\n",
      "2017-10-30 00:38:19 Iter 200: batch trn loss = 0.538, accuracy = 0.800\n",
      "2017-10-30 00:38:39 Iter 300: batch trn loss = 0.788, accuracy = 0.720\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('train: epoch %d' % i)\n",
    "    cnn.train(m_X_trn, y_trn, epochs=1, batch_size=50, print_every=100, plot_losses=False)\n",
    "    print('validation')\n",
    "    cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0112]\n",
    "- base (0110)\n",
    "- first combination from conv-bn-pool --> conv-pool-bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(layer_input, labels, is_training):\n",
    "    reg_scale= 0.1\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=reg_scale)\n",
    "    regularizer = None\n",
    "    F1 = 32\n",
    "    layer = tf.layers.conv2d(inputs=layer_input, filters=F1, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, \n",
    "                             kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    F2 = 64\n",
    "    layer = tf.layers.conv2d(inputs=layer, filters=F2, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "                            kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    flat_size = int(H / 4 * W / 4 * F2)\n",
    "    print(flat_size)\n",
    "    layer = tf.reshape(layer, [-1, flat_size])\n",
    "    layer = tf.layers.dense(inputs=layer, units=1024,\n",
    "                           kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer_logit = tf.layers.dense(inputs=layer, units=T,\n",
    "                                 kernel_regularizer=regularizer)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int64), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=layer_logit)\n",
    "    return layer_logit, loss\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "cnn = CNN(model_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print('train: epoch %d' % i)\n",
    "    cnn.train(m_X_trn, y_trn, epochs=1, batch_size=50, print_every=100, plot_losses=False)\n",
    "    print('validation')\n",
    "    cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0113]\n",
    "- base (0112)\n",
    "- F1: 32 --> 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(layer_input, labels, is_training):\n",
    "    reg_scale= 0.1\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=reg_scale)\n",
    "    regularizer = None\n",
    "    F1 = 64\n",
    "    layer = tf.layers.conv2d(inputs=layer_input, filters=F1, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, \n",
    "                             kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    F2 = 64\n",
    "    layer = tf.layers.conv2d(inputs=layer, filters=F2, kernel_size=[5, 5], padding='same', activation=tf.nn.relu,\n",
    "                            kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer = tf.layers.max_pooling2d(inputs=layer, pool_size=[2, 2], strides=2)\n",
    "    flat_size = int(H / 4 * W / 4 * F2)\n",
    "    print(flat_size)\n",
    "    layer = tf.reshape(layer, [-1, flat_size])\n",
    "    layer = tf.layers.dense(inputs=layer, units=1024,\n",
    "                           kernel_regularizer=regularizer)\n",
    "    layer = tf.layers.batch_normalization(inputs=layer, training=is_training)\n",
    "    layer_logit = tf.layers.dense(inputs=layer, units=T,\n",
    "                                 kernel_regularizer=regularizer)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int64), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=layer_logit)\n",
    "    return layer_logit, loss\n",
    "\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "cnn = CNN(model_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print('train: epoch %d' % i)\n",
    "    cnn.train(m_X_trn, y_trn, epochs=1, batch_size=50, print_every=100, plot_losses=False)\n",
    "    print('validation')\n",
    "    cnn.validate(m_X_val, y_val, epochs=1, batch_size=y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
